---
title: Calculate aggregate for grouped rows based on column value, DAX version
tag: logo-powerbi
date: October 24, 2021
---

How to use DAX to find the aggregate value for rows grouped by a column value in Power BI.

In a __[previous post](https://datamesse.github.io/#/post/1634389200/)__, I wrote on window aggregation equivalents in Power Query, going on the notion that categorical columns are generally better off done in Power Query using M code, as opposed to done in DAX.

However, in a Power BI report I am working on, it seemed re-implementing it using DAX had faster report load times than Power Query, which I attributed to existing Power Query merges needed for the model, which slowed down processing. It also required having 2 columns in the model (one for the aggregation, and the other for the conditional result), unlike DAX which only required one.

That M code looked like this:

**Power Query M structure**
```
    #"Added Custom 1" = Table.NestedJoin(#"Previous step",
                                      {"Column A to join on"},
                                      Table.Group(Table.SelectRows(#"Changed Type", each ([Column C] = "Agent")),
                                                  {"Column A to join on"},
                                                  {{"Result of aggregation",
                                                  each List.Min([#"Column B to aggregate on"]), type nullable datetime}}),
                                      {"Column A to join on"},
                                      "Merged group by table",
                                      JoinKind.Inner),
    #"Expanded Merged group by table" = Table.ExpandTableColumn(#"Added Custom 1", "Merged group by table", {"Result of aggregation"}, {"Result of aggregation"}),
    #"Added Custom 2" = Table.AddColumn(#"Expanded Merged group by table", "M column result", each if [#"Column B to aggregate on"] = [#"Result of aggregation"] then "Yes" else "No")
```

In this example we're still using randomised support ticket update data, and trying to find which agent reply to the user is the first for each Ticket ID.

![Sample dataset with only 15 rows of data](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--01.png?raw=true)


**Power Query implementation**
```
    #"Added Custom" = Table.NestedJoin(#"Changed Type",
                                      {"Ticket ID"},
                                      Table.Group(Table.SelectRows(#"Changed Type", each ([Updater role] = "Agent")),
                                                  {"Ticket ID"},
                                                  {{"Earliest date/time by Ticket ID",
                                                  each List.Min([#"Update - Timestamp"]), type nullable datetime}}),
                                      {"Ticket ID"},
                                      "Merged group by table",
                                      JoinKind.Inner),
    #"Expanded Merged group by table" = Table.ExpandTableColumn(#"Added Custom", "Merged group by table", {"Earliest date/time by Ticket ID"}, {"Earliest date/time by Ticket ID"}),
    #"Added Custom1" = Table.AddColumn(#"Expanded Merged group by table", "1st reply?", each if [#"Update - Timestamp"] = [#"Earliest date/time by Ticket ID"] then "Yes" else "No")
in
    #"Added Custom1"
```

![Sample dataset with only 15 rows of data Power Query M code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--02.png?raw=true)


![Sample dataset with only 15 rows of data Power Query performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--03.png?raw=true)

Now let's look at the DAX alternative.

In DAX, we've coded it as a new column, where an initial if condition is used to pre-determine the result for invalid rows (such as messages from client), and the nested false condition checks the remaining canidate rows (messages from agents) to see if the aggregate value (i.e. the earliest *Update - Timestamp*) matches for the existing row for each Ticket ID group.

![Sample dataset with only 15 rows of data DAX Add New Column](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--04.png?raw=true)

**DAX structure**
```
DAX column = IF([Column C] = "Column value of rows that should be excluded from aggregation",
                "No",
                IF(Tablename[Column B to aggregate on] = 
                    CALCULATE (
                               MIN ( Tablename[Column B to aggregate on] ),
                               FILTER(ALLEXCEPT (Tablename, Tablename[Column A to join on]), Tablename[Column C] = "Column value of rows to aggregate on" ))
                              ,"Yes"
                              ,"No"
                )
             )
```

**DAX implementation**
```
1st reply? = IF([Updater role] = "Client",
                "No",
                IF(Updates1[Update - Timestamp] = 
                    CALCULATE (
                               MIN ( Updates1[Update - Timestamp] ),
                               FILTER(ALLEXCEPT (Updates1, Updates1[Ticket ID]), Updates1[Updater role] = "Agent" ))
                              ,"Yes"
                              ,"No"
                )
             )
```

![Sample dataset with only 15 rows of data DAX code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--05.png?raw=true)


![Sample dataset with only 15 rows of data DAX performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--06.png?raw=true)


Comparing the initial table refreshes from the screenshots above seems to indicate Power Query in this scenario is more performant than DAX.
* DAX: 224ms
* Power Query: 94ms

However, this is a flat dataset with only 15 rows. So I set out to test it with a larger flat dataset (27780 rows), and if the results still show Power Query is more performant than DAX for categorical window aggregation, I would test a second time with that larger dataset, but using pre-existing merges to more closer reflect my model.


**COMPARING DAX AND M FOR CATEGORICAL WINDOW AGGREGATION**

This blog post compares DAX vs Power Query (M) implementation of this scenario against:
1. flat dataset using M for the window aggregation column
2. flat dataset using DAX for the window aggregation column
3. dataset with existing merge using M for the window aggregation column
4. dataset with existing merge using DAX for the window aggregation column

**Test 1: Flat dataset using M for the aggregation column**

![Large flat dataset using M window aggregation M code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--07.png?raw=true)

Note: Refresh 1 is when the column is first added to the visual.

![Large flat dataset using M performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--09.png?raw=true)


**Test 2: Flat dataset using DAX for the aggregation column**

![Large flat dataset using M window aggregation DAX code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--08.png?raw=true)


![Large flat dataset using DAX](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--10.png?raw=true)

Now we've applied a simple merge to the dataset to display additional columns.
![Large dataset with existing merge](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--11.png?raw=true)


**Test 3: Merged dataset using M for the aggregation column**

![Large dataset with existing merge using M performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--12.png?raw=true)


![Large dataset with existing merge using DAX performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--15.png?raw=true)


**Test 4: Merged dataset using DAX  for the aggregation column**

![Large dataset with existing merge using DAX](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--13.png?raw=true)


![Large dataset with existing merge using DAX performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--14.png?raw=true)


![Large dataset with existing merge using DAX performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--16.png?raw=true)

Reviewing these table refresh times, it appears that for data sources involving a merge, using DAX for window aggregations is more performant than using Power Query, whereas it seems to be the reverse for data sources not involving merges.

![Comparing table refresh times](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--17.png?raw=true)

Click **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2021-10-24.md)** for this post's markdown file in GitHub.