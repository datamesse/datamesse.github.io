---
title: Find grouped records with a date that matches another date column using DAX
tech: POWER BI
tag: logo-powerbi
date: 27 February 2022
---

How to use DAX to group records by an identity column, and see if the most recent row has a date value that matches a date value in another column.

In previous posts I've tried to find __[window aggregate values using DAX](https://datamesse.github.io/#/post/1634994000)__, and as many Power BI developers highlight, there are many ways to get the same outcome. However the difference between that previous post and this one is that the prior one applied a value to a specific row of the group, whereas this one applies the value to all rows of each grouping, which will be needed for other calculated columns.

Whilst working on a small data integrity report at work, I came across this method which is a slightly modified script from a Power BI Communities post, intended to pull the desired value per grouping and apply it to all rows of each group.

**DAX structure**
```
Custom column 1 =
VAR identifiercolumn = 'Table'[ID column]
VAR findlatestrecord = CALCULATE( MAX( 'Table'[Date A] ), ALLEXCEPT( 'Table', 'Table'[ID column] ) )
RETURN
   CALCULATE ( 
              MAX( 'Table'[Date A] ),
              FILTER( 'Table', 'Table'[Date A] = findlatestrecord ),
                      'Table'[ID column] = identifiercolumn               
   )
```
What should be noted is the aggregation under RETURN doesn't matter in this case i.e. it could be MIN or MAX, because the second declared variable targets the specific row to get its value from, rather than actually aggregating all values for the group.

The scenario I applied this to involves a series of flat files produced on separate days to represent historic and future orders. Each order is scheduled to be delivered on a specific date at a certain cost. The report is intended to highlight problematic data, such as Order IDs that were scheduled for a specific date in one file, but do not appear in the other files generated on that same date.

In this context, we want to know the most recent *Planned Delivery Date* applied to an *Order ID* based on the latest *File's date* that the *Order ID* appears in, then apply that value to all the rows for that *Order ID*

In the example below, there are 2 Order IDs, 8 and 9. *Order ID* 8 has its *Planned Delivery Date* moved earlier, and *Order ID* 9 has its own moved later, in subsequent files. The ones highlighted orange are the ones we want to display.

![Sample dataset 1](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-02-27--01.png?raw=true)

Applying the above DAX structure, we get the following:

**DAX implementation**
```
Most recent Planned Delivery Date = 
VAR orderid = 'Data integrity audit'[Order ID]
VAR highestfiledatebyorderid =
    CALCULATE(
        MAX( 'Data integrity audit'[File's date] ), ALLEXCEPT( 'Data integrity audit','Data integrity audit'[Order ID] )
    )
RETURN
    CALCULATE(
        MAX ( 'Data integrity audit'[Planned Delivery Date] ),
        FILTER( 'Data integrity audit', 'Data integrity audit'[File's date] = highestfiledatebyorderid ),
                'Data integrity audit'[Order ID] = orderid
    )
```

![Applied DAX structure to find recent date value by Order ID](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-02-27--02.png?raw=true)

![Successfully applied DAX column added to table 1](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-02-27--03.png?raw=true)

Now that we have applied the most recent *Planned Delivery Date* for every row based on *Order ID* as an anchor, we just need to check to if the *Order ID* has a row reflecting that it appears in a file whose generation date is the same as the most recent *Planned Delivery Date*. In this context, it serves as affirmation that it was delivered on that day.

**DAX structure**
```
Custom column 2 =
IF (
    ISBLANK(
            CALCULATE(
               FIRSTNONBLANK( 'Table'[ID column], 1 ),
               FILTER( ALLEXCEPT( 'Table', 'Table'[ID column] ),
                                  'Table', 'Table'[Custom column 1] = 'Table'[Date B]               
               )
            )
    )
)
```

Looking at *Order ID* examples 8 and 16, the former has a matchng record and the latter does not.

![Sample dataset 2](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-02-27--04.png?raw=true)

**DAX implementation**
```
Does Order ID appear in File with date matching Delivery Date? = 
IF(
    ISBLANK(
        CALCULATE(
            FIRSTNONBLANK('Data integrity audit'[Order ID], 1),
            FILTER( ALLEXCEPT('Data integrity audit','Data integrity audit'[Order ID] ),
                              'Data integrity audit'[Most recent Planned Delivery Date] = 'Data integrity audit'[File's date] )
        )
    ) = FALSE,
    "Yes",
    "No"
)
```

![Applied DAX structure to match different date columns and apply to all records per group](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-02-27--05.png?raw=true)

![Successfully applied DAX column added to table 2](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-02-27--06.png?raw=true)

Other more complex columns can then be built on top of this one, in my case, creating a conditional column that categorises the different patterns to highlight areas where data integrity may require review.

![Complex conditional DAX query built on top of the aforementioned queries](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-02-27--07.png?raw=true)

![Example categorisation from previous query added to a matrix](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-02-27--08.png?raw=true)

Click **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2022-02-27.md)** for this post's markdown file in GitHub.
