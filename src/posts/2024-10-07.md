---
title: Create a machine learning Windows server using AWS EC2, TensorFlow, and Python
tech: PYTHON
tag: logo-python
date: 07 October 2024
---

This post is a guide on how to set up an AWS EC2 on-demand server with Windows OS, and an NVIDIA graphics card for machine learning via TensorFlow. 

Requirements (i.e. areas this post does not cover):
- AWS account with payment method **[https://docs.aws.amazon.com/SetUp/latest/UserGuide/setup-AWSsignup.html](https://docs.aws.amazon.com/SetUp/latest/UserGuide/setup-AWSsignup.html)**
- Understand how to create a security group and keypair
- Understand how to RDP into an AWS instance using a keypair

**Note:** This guide is by no means a must setup to study machine learning. It's more of a reminder to myself on how to do the setup using my preferred tools, Windows and Visual Studio Code. 

There are free alternatives where you do not need to perform this kind of setup, for example: **[https://colab.research.google.com](https://colab.research.google.com)**.



## Step 1. Create an EC2 g4dn instance type in AWS

From the AWS EC2 dashboard, launch an instance. 

Under the **Application and OS Images** section, select Windows, then a free tier eligible Amazon machine image. In this example we have selected _"Microsoft Windows Server 2022 Base"_.

Now here is the first component of our setup that will incur the on-demand cost (based on your usage). Under the **Instance type** section, select g4dn.xlarge. 

The g4dn instance is intended for high performance computing using GPU acceleration, which machine learning can require. Amongst the g4dn configurations we can choose from, xlarge has the lowest RAM (16GB) and therefore the lowest hourly cost (as at time of writing). There are other options which go into hundreds of GBs of RAM as well, but they are just a bit more expensive...

![AWS EC2: Launch an instance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--01.png?raw=true)

If you recently created your personal AWS account, you likely cannot make the above selection, and receive this warning instead:

_"You have requested more vCPU capacity than your current vCPU limit of 0 allows for the instance bucket that the specified instance type belongs to. Please visit http://aws.amazon.com/contact-us/ec2-request to request an adjustment to this limit."_

![AWS EC2: vCPU limit warning](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--02.png?raw=true)

If this is the case for you, navigate to the Service Quotas dashboard, then search for _Running On-Demand G and VT instances_.

![AWS Service Quotas: Request increase at account level ](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--03.png?raw=true)

Select that Quota name, and click the _"Request increase at account level"_ button. You will be prompted to explain the reason for your quota's extension. In my case, I explained I was self-studying machine learning and the tutorial I was following recommended the g4dn instance type.

Your request is be submitted to AWS staff who will revise it for security purposes, and it may take a couple of days to be fulfilled. Once your request is successful, then re-attempt the above EC2 instance creation.

If you are successful in selecting the g4dn.xlarge Instance type, proceed to add your security group in the **Network settings** section.

The amount of hard drive space you define under **Configure storage** will also incur ongoing cost. Free tier eligibility for storage caps out at 30GB (as at time of writing). However, the completed setup of the server needs at least 40GB of hard drive space. In this example, 50GB of storage is defined.

![AWS EC2: Configure storage](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--04.png?raw=true)



## Step 2. Check TensorFlow's GPU compatibility list

Next, we start planning the components to install on our Windows Server to allow for computation using its GPU. As we will be combining components from different platforms i.e. NVIDIA, TensorFlow, Python, and Microsoft, we will need to be mindful of compatibility.

You can find compatibility charts on TensorFlow's website that identifies platform combinations they have successfully tested, under the **GPU** section.

**[https://www.tensorflow.org/install/source_windows](https://www.tensorflow.org/install/source_windows)**

![TensorFlow: GPU compatibility](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--05.png?raw=true)

Based on this chart, we will try to install platforms as close to the versions listed below, as we can.
 - NVIDIA GPU driver that supports CUDA Toolkit version 11.2
 - a Python version between 3.7 and 3.10
 - CUDA Toolkit version 11.2
 - cuDNN version 8.1
 - Microsoft Visual C++ Compiler (MSVC) version 2019
 - create a virtual environment with tensorflow-gpu version 2.10.0 installed

We will also install:
 - DirectX End-User Runtimes: to help check that the GPU is recognised by Windows.


Once your Windows instance is running, remote into it.



## Step 3. Install NVIDIA GPU driver

From Device Manager, under _Other devices \ 3D Video Controller_, the graphics card appears to be missing a driver.

![Device Manager: 3D Video Controller](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--06.png?raw=true)


So we will install one from NVIDIA's website.

AWS's g4dn EC2 instances use T4 GPUs, so we'll attempt to install this.

**[https://www.nvidia.com/en-us/drivers](https://www.nvidia.com/en-us/drivers)**

![NVIDIA: Data Center Driver for Windows](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--07.png?raw=true)

In this example, we will use the _Data Center Driver for Windows version 475.14_, as this is the closest to version 11.2 we can find.

**[https://www.nvidia.com/en-us/drivers/details/228678](https://www.nvidia.com/en-us/drivers/details/228678)**

![NVIDIA: Data Center Driver for Windows download](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--08.png?raw=true)

![NVIDIA: Graphics Driver installed](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--09.png?raw=true)

Once the graphics driver is installed, you should be able to view it under Display adapters in Device Manager.

![Device Manager: NVIDIA Tesla T4](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--10.png?raw=true)

 - _NVIDIA GPU driver that supports CUDA Toolkit version 11.2_
 - **a Python version between 3.7 and 3.10**
 - **CUDA Toolkit version 11.2**
 - **cuDNN version 8.1**
 - **Microsoft Visual C++ Compiler (MSVC) version 2019**
 - **create a virtual environment with tensorflow-gpu version 2.10.0 installed**
 - **DirectX End-User Runtimes**



## Step 4. Install Python

Next we will install a Python version between 3.7 and 3.10.

**[https://www.python.org/downloads/windows](https://www.python.org/downloads/windows)**

In this example, we will use Python version 3.9.12. No particular reason on this one.

![Python: 3.9.12 installer](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--11.png?raw=true)

Ensure the option to add Python to the environmental PATH is ticked during the install.

![Python: Setup was successful](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--12.png?raw=true)

 - _NVIDIA GPU driver that supports CUDA Toolkit version 11.2_
 - _a Python version between 3.7 and 3.10_
 - **CUDA Toolkit version 11.2**
 - **cuDNN version 8.1**
 - **Microsoft Visual C++ Compiler (MSVC) version 2019**
 - **create a virtual environment with tensorflow-gpu version 2.10.0 installed**
 - **DirectX End-User Runtimes**



## Step 5. Install DirectX End-User Runtimes

For this step, we will install the DirectX End-User Runtimes.
The reason for this is to help cover potentially missing components using this method of TensorFlow installation, versus TensorFlow's official guide which may target personal Windows machines for local development.

The link below is for the offline DirectX installer, as for whatever reason, the online installer didn't work for me.

**[https://www.microsoft.com/en-us/download/details.aspx?id=8109](https://www.microsoft.com/en-us/download/details.aspx?id=8109)**

![DirectX: End-User Runtimes download](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--13.png?raw=true)

![DirectX: Installation Complete](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--14.png?raw=true)

 - _NVIDIA GPU driver that supports CUDA Toolkit version 11.2_
 - _a Python version between 3.7 and 3.10_
 - **CUDA Toolkit version 11.2**
 - **cuDNN version 8.1**
 - **Microsoft Visual C++ Compiler (MSVC) version 2019**
 - **create a virtual environment with tensorflow-gpu version 2.10.0 installed**
 - _DirectX End-User Runtimes_

Now that the graphics card's registration on the server is done, we'll install the components needed to take advantage of it for computation.



## Step 6. Install CUDA Toolkit

The CUDA Toolkit is what allows the GPU (graphics card) to handle processing that would typically be reserved for the CPU (processor). Namely, the AI tasks from the projects you will hopefully create.

NVIDIA's GPU compatibility guide indicated CUDA version 11.2, but as that was no longer available in the CUDA Toolkit Archive, I went with version 11.4.0.

**[https://developer.nvidia.com/cuda-toolkit-archive](https://developer.nvidia.com/cuda-toolkit-archive)**

![NVIDIA: CUDA Toolkit 11.4.0](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--15.png?raw=true)

Although there is no Server 2022 option, Server 2019 should work or our purposes.

![NVIDIA: CUDA Toolkit 11.4.0 Downloads](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--16.png?raw=true)

![NVIDIA: Nsight Visual Studio Edition Summary](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--17.png?raw=true)

 - _NVIDIA GPU driver that supports CUDA Toolkit version 11.2_
 - _a Python version between 3.7 and 3.10_
 - _CUDA Toolkit version 11.2_
 - **cuDNN version 8.1**
 - **Microsoft Visual C++ Compiler (MSVC) version 2019**
 - **create a virtual environment with tensorflow-gpu version 2.10.0 installed**
 - _DirectX End-User Runtimes_



## Step 7. Install cuDNN

Next we install the cuDNN (cuda Deep Neural Network) library, which is used to optimise the deep learning computations.

The cuDNN Archive lists a ranged installer version (8.x - 1.x) that covers the cuDNN version we were aiming for, version 8.1.

**[https://developer.nvidia.com/cudnn-archive](https://developer.nvidia.com/cudnn-archive)**

![NVIDIA: cuDNN Archive 8.x - 1.x](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--18.png?raw=true)

![NVIDIA: cuDNN Library for Windows](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--19.png?raw=true)

The contents of the cuDNN zip mirrors the file structure of the CUDA installation.
So all you should need to do is copy the bin, include, and lib folders from the cuDNN zip...

![NVIDIA: Copy cudnn files](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--20.png?raw=true)

... then paste them into your CUDA installation, which should be at C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.4 assuming you accepted the defaults from Step 6.

![NVIDIA: Paste cudnn files into GPU Computing Toolkit CUDA](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--21.png?raw=true)

Go into Windows' Environmental Variables, and ensure that the System variable Path has the appropriate CUDA references.

In this example, the following were already added to Path via the earlier installation:
* C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.4\bin
* C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.4\libnvvp

But I needed to manually add this library version reference:
* C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.4\bin

![Environmental Variable: Add CUDA lib x64 folder](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--22.png?raw=true)

 - _NVIDIA GPU driver that supports CUDA Toolkit version 11.2_
 - _a Python version between 3.7 and 3.10_
 - _CUDA Toolkit version 11.2_
 - _cuDNN version 8.1_
 - **Microsoft Visual C++ Compiler (MSVC) version 2019**
 - **create a virtual environment with tensorflow-gpu version 2.10.0 installed**
 - _DirectX End-User Runtimes_



## Step 8. Test installations from Command Prompt

To test our installations, we can run the following via Command Prompt:

* Verify the cuDNN installation by checking this command returns its version number.

```
nvcc --version
```

* Verify the NVIDIA installation by checking the GPU is identifiable. 

In the screenshot below, you can see the 15205MiB Tesla T4 GPU has been assigned an identifier of 0. Note: This GPU:0 is just an index reference, and if there were more GPUs attached, they'd be sequentially ordered, e.g. GPU:0, GPU:1, GPU:2, etc.

```
nvidia-sim
```

* Verify the Python installation by checking this command returns its version number.

```
python --version
```

![Command Prompt: Test nvcc, nvidia card, and Python version](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--23.png?raw=true)



## Step 9. Install Microsoft C++ Build Tools

Even though this environment is intended for Python development, we may need to install the Microsoft Visual C++ Compiler in order to potentially work with certain custom TensorFlow extensions, given TensorFlow's backend is built on C++.

You can find the standalone installer here:
* **[https://visualstudio.microsoft.com/visual-cpp-build-tools](https://visualstudio.microsoft.com/visual-cpp-build-tools)**

![Microsoft C++ Build Tools download](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--24.png?raw=true)

For the installation, from the Workloads tab tick _"Desktop development with C++"_, and in the Installation details pane, we're ticking:
* MSVC 2019 as per the compatibility guide
* MSVC 2022 because it is the latest and therefore a dependency of Desktop development with C++
* C++ CMake tools for Windows - for custom TensorFlow or CUDA extensions

![Installing Visual Studio Build Tools 2019](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--25.png?raw=true)

![Visual Studio Build Tools 2022](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--26.png?raw=true)

 - _NVIDIA GPU driver that supports CUDA Toolkit version 11.2_
 - _a Python version between 3.7 and 3.10_
 - _CUDA Toolkit version 11.2_
 - _cuDNN version 8.1_
 - _Microsoft Visual C++ Compiler (MSVC) version 2019_
 - **create a virtual environment with tensorflow-gpu version 2.10.0 installed**
 - _DirectX End-User Runtimes_



## Step 10. Install Visual Studio Code and extensions

Now onto the all so familiar and easy task of installing Visual Studio Code...

* **[https://code.visualstudio.com/Download](https://code.visualstudio.com/Download)**

![Download Visual Studio Code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--27.png?raw=true)

![Visual Studio Code Setup Wizard Completed](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--28.png?raw=true)

...and the Python Extension for Visual Studio Code.

![Visual Studio Code: Python Extension](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--29.png?raw=true)



## Step 11. Create project and virtual Python environment with tensorflow

Next we're going to create a Python project to test the GPU.

In this example, I've created a folder C:\Project\TensorFlow-Python and opened it via Visual Studio Code.

![Visual Studio Code: Create project folder](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--30.png?raw=true)

Then via a Command terminal within Visual Studio Code, we execute the following:

* Creating a virtual environment to install our Python packages into.

```
python -m venv C:\Projet\TensorFlow-Python\venv
```

* Activate said virtual environment into the terminal

```
venv\Scripts\activate
```

![Visual Studio Code: Create virtual Python environment](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--31.png?raw=true)

Next, we install the tensorflow-gpu Python package, specifically version 2.10.0 as per the compatibility guide.

```
pip install tensorflow-gpu==2.10.0
```

![Visual Studio Code: Install tensorflow_gpu into virtual environment](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--32.png?raw=true)

 - _NVIDIA GPU driver that supports CUDA Toolkit version 11.2_
 - _a Python version between 3.7 and 3.10_
 - _CUDA Toolkit version 11.2_
 - _cuDNN version 8.1_
 - _Microsoft Visual C++ Compiler (MSVC) version 2019_
 - _create a virtual environment with tensorflow-gpu version 2.10.0 installed_
 - _DirectX End-User Runtimes_

That's all items ticked off now, but there's just a little more to do.

Even though tensorflow-gpu is installed into my virtual environment, I was not able to import TensorFlow into my Python script, because my numpy version (2+) was incompatible.

Thus, I reinstalled numpy by targeting a lower version.

```
pip install numpy==1.23.5
```

![Visual Studio Code: Install lower numpy version](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--33.png?raw=true)

From that same cmd Terminal session, I ran the following script to check I could import tensorflow and detect the GPU.

```
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

The indication of GPU:0 in the screenshot below is my confirmation.

![Visual Studio Code: Test recognition of GPU](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--34.png?raw=true)

Lastly, I ran a Python script (courtesy of ChatGPT as most of this article was guided from), to see if the calculation against the GPU would occur, and it was successful.

```
import tensorflow as tf

# Create a simple tensor and perform a computation
with tf.device('/GPU:0'):
    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
    b = tf.constant([[1.0], [2.0], [3.0]])
    c = tf.matmul(a, b)

print(c)
```

![Visual Studio Code: Test GPU calculation by creating tensor](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--35.png?raw=true)

Now we have a process and an instance of Windows running TensorFlow with Python using an NVIDIA graphics card.

As a side note, after completing all these installations, I have about 9.5GB remaining storage space.

![Check hard drive space](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2024-10-07--36.png?raw=true)



### References

* **[ChatGPT 3.5](https://chat.openai.com/)**

* YouTube video **[Deep Learning on Cloud using Amazon AWS | EC2 GPU Instance by Sagar G. Sangodkar](https://www.youtube.com/watch?v=B75B-JBmyDw&t=559s)**



Click **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2024-10-07.md)** for this post's markdown file in GitHub.