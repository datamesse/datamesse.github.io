---
title: How to webscrape recent Twitter posts by keyword using Python and Visual Studio Code
tag: logo-python
date: July 31, 2022
---

This post shows how to webscrape recent Tweets based on a predefined keyword or hashtag, and other related data using the Twitter API, Visual Studio Code, and the Python-based Tweepy library.

## Step 1. Create a free Twitter Developer account

As at the time of writing, you can get a Twitter Developer account off the back of an existing Twitter account or create a new one, but you will need to provide your mobile phone number for verification.

* **[https://developer.twitter.com/](https://developer.twitter.com/)**

From the Twitter Developer Portal, you can create your project and app, and then additionally request for Elevated access, which provides higher level Twitter API accesses and limits. Be mindful that your application may incur costs depending on the features you request, and in my case, I chose free Read-Only access.

![Developer Portal: Project](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-07-31--01.png?raw=true)

Generate the API Key, Access Tokens, and Secrets that will be needed for your API connection, being careful that data is ssecurely stored.

![Developer Portal: Keys and tokens](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-07-31--02.png?raw=true)


## Step 2. From Visual Studio Code install Python and set up your virtual environment

Install Python
* **[https://www.python.org/downloads/windows/](https://www.python.org/downloads/windows/)**

Create a folder for your Python project and open it in Visual Studio Code. In this example, the folder name is *twitter-web-scraping*.

Install the Python Extension for Visual Studio Code.
![Visual Studio Code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-04-17--01.png?raw=true)

Create your virtual environment as a subfolder of your project.
```
python -m venv C:\Project\twitter-web-scraping\venv
```

You can find more detailed screenshot steps of the above from a previous blog post:
* **[Add forecasts from Python using Visual Studio Code to Power BI](https://datamesse.github.io/#/post/1650117600)**

## Step 3. Install relevant Python libraries

```
pip install tweepy
pip install configparser
pip install pandas
```

## Step 4. Create a configuration file to store your Twittter API keys, tokens, and secrets

Create a config.ini file in your project folder, and add your API keys, tokens, and secrets in place of the ???? below.

**config.ini**
```
[twitter]

api_key = ????
api_key_secret = ????

access_token = ????
access_token_secret = ????
```

Be very careful not to publish these details publically, such as via Github.

![Visual Studio Code: config.ini](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-07-31--03.png?raw=true)


## Step 5. Create a Python script to run the Tweet extraction

This Python script uses the keys, tokens, and secrets by referencing the config.ini from the previous step.

In the example below, the keyword search being used is "Motorola". Simply substitute that value for your preferred text string, or hashtag.

At the time of my testing, I can only retrieve a maximum of about 900 records every 15 minutes using my elevated API, and have coded that as part of the script's limit so it doesn't error out when it is executed.

**Note:** tweet.text appears to be a truncated variation of the Tweet data, whereas tweet.full_text scrapes the full Tweet.

Because the data is saved to a CSV file, new lines and commas are replaced with space characters to keep the data to single row records.

**python_script.py**
```
import tweepy
import configparser
import pandas as pd

config = configparser.ConfigParser()
config.read('config.ini')
api_key = config['twitter']['api_key']
api_key_secret = config['twitter']['api_key_secret']
access_token = config['twitter']['access_token']
access_token_secret = config['twitter']['access_token_secret']

auth = tweepy.OAuthHandler(api_key,api_key_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)

keywords = ['Motorola']

limit = 901
tweets = tweepy.Cursor(api.search_tweets, q=keywords, lang='en', result_type='recent', tweet_mode="extended").items(limit)

columns = ['TweetDateTime', 
           'UserID',
           'UserName',
           'UserScreenName',
           'UserDescription',
           'UserCreatedDateTime',
           'UserVerified',
           'UserLocation',
           'UserFollowers',
           'TweetContent',
           'TweetFavourites',
           'TweetRetweets']
data = []
for tweet in tweets:
    data.append([tweet.created_at,
                 tweet.user.id, 
                 tweet.user.name.replace('\n', ' ').replace(',',' '),
                 tweet.user.screen_name.replace('\n', ' ').replace(',',' '),
                 tweet.user.description.replace('\n', ' ').replace(',',' '),
                 tweet.user.created_at,
                 tweet.user.verified,
                 tweet.user.location.replace('\n', ' ').replace(',',' '),
                 tweet.user.followers_count,
                 tweet.full_text.replace('\n', ' ').replace(',',' '),
                 tweet.favorite_count,
                 tweet.retweet_count])
df = pd.DataFrame(data, columns=columns)
df.to_csv('tweets.csv')
```

![Visual Studio Code: python_script.py](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2022-07-31--04.png?raw=true)


### References

* YouTube video **["How to get TWEETS by Python | Twitter API 2022" by AI Spectrum](https://www.youtube.com/watch?v=Lu1nskBkPJU)**

* YouTube video **["Get TWEETS by User and Hashtag with Python | Twitter API 2022" by AI Spectrum](https://www.youtube.com/watch?v=FmbEhKSpR7M)**

* YouTube video **["how to automate search of trending hashtag and number of tweets from those hashtags" by iknowpython](https://www.youtube.com/watch?v=ywl--vO3oGs)**

* Twitter API v1 Search Tweets Reference **[https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets)**

* Twitter API v2 data dictionary **[https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet)**

* Tweepy library Exteded Tweets **[https://docs.tweepy.org/en/stable/extended_tweets.html](https://docs.tweepy.org/en/stable/extended_tweets.html)**


Click **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2022-07-31.md)** for this post's markdown file in GitHub.