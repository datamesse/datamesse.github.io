(this["webpackJsonpdatamesse.github.io"]=this["webpackJsonpdatamesse.github.io"]||[]).push([[0],{13:function(e){e.exports=JSON.parse('[{"id":1639746000,"title":"How to create a free Azure account to post reports to the Power BI Gallery","tag":"logo-azure","date":"December 18, 2021","content":"\\r\\nIf your work or school account does not provide you access to Power BI (for the purposes of publishing to Web, specifically the Community Gallery), you can create your own. \\r\\n\\r\\nYou can check your existing account by navigating to **[https://powerbi.microsoft.com/](https://powerbi.microsoft.com/)**, then clicking \\"Have an account? Sign in\\".\\r\\n\\r\\n![Check Power BI sign in](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--01.png?raw=true)\\r\\n\\r\\nIf you receive the following message:\\r\\n\\r\\n*\\"Sorry, we can\'t sign you up as ...*\\r\\n\\r\\n*Your IT department has turned off signup for Microsoft Power BI. Contact them to complete signup.\\"*\\r\\n\\r\\n![Power BI sign up disabled](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--02.png?raw=true)\\r\\n\\r\\n...and have no sway over your IT department to give you access, you can sign up or a new account instead by clicking \\"No account? Create one!\\", and set up your new email and password.\\r\\n\\r\\n![Azure Sign in create account](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--03.png?raw=true)\\r\\n\\r\\n![Azure create a new account](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--04.png?raw=true)\\r\\n\\r\\nYou can then start your Azure free trial. Fill out your details, which will require providing a mobile number for identity verification.\\r\\n\\r\\n![Azure portal](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--05.png?raw=true)\\r\\n\\r\\nWith your account set up, you can now begin creating your own \\"organisation\\" or tenant, which would have Power BI enabled. Begin by going to Azure Active Directory.\\r\\n\\r\\n![Azure Active Directory](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--06.png?raw=true)\\r\\n\\r\\nClick \\"Manage tenants\\", and create your new tenant.\\r\\n![Azure Active Directory Manage tenants](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--07.png?raw=true)\\r\\n\\r\\nThen create a new user under that tenant domain e.g. yourname@yourtennt.onmicrosoft.com, and ensure that new user is added to the Administrators group of the tenant.\\r\\n\\r\\n![Azure Active Directory Add User](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--08.png?raw=true)\\r\\n\\r\\nFor that new user account, assign the roles Power BI Administrator and Power Platform admin, which you can do from **[https://portal.office.com](https://portal.office.com)**.\\r\\n\\r\\n![Microsoft 365 admin center](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--09.png?raw=true)\\r\\n\\r\\nThen you can configure \\"Publish to Web\\" from the Admin portal at **[https://app.powerbi.com](https://app.powerbi.com)**. There are plenty of other resources for setup recommendations. For example, this post from **[Radacad](https://radacad.com/power-bi-administrator-tenant-settings-configuration-you-dont-dare-to-miss)**.\\r\\n\\r\\n![Power BI Admin portal](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-12-18--10.png?raw=true)\\r\\n\\r\\nClick **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2021-12-18.md)** for this post\'s markdown file in GitHub."},{"id":1635598800,"title":"Customer support ticket update generator and sample dataset","tag":"logo-excel","date":"October 31, 2021","content":"\\r\\nThis is a sample dataset created using Excel randomisation, and you can create your own using the file generator.\\r\\n\\r\\nYou can download or connect to the sample dataset from **[here](https://github.com/datamesse/data-visualisation-datasets/blob/main/Support%20ticket%20updates/Support%20ticket%20updates.xlsx?raw=true)**.\\r\\n\\r\\nThe Github repository with the agent photos can be found **[here](https://github.com/datamesse/data-visualisation-datasets/tree/main/Support%20ticket%20updates/agents)**.\\r\\n\\r\\nAn Excel random person name and business generator was also used to create this dataset, downloadable **[here](https://github.com/datamesse/data-visualisation-datasets/blob/main/Support%20ticket%20updates/Random%20name%20and%20business%20generator.xlsx?raw=true)**.\\r\\n\\r\\nThe dataset contains:\\r\\n - 5000 support tickets\\r\\n - 27780 support ticket update records\\r\\n - 29 agents across 8 countries and 12 cities\\r\\n - 1233 end users across 27 countries and 65 cities\\r\\n - Date/timestamps are based on Sydney, Australia time (AEST GMT+10/AEDT GMT+11)\\r\\n\\r\\nThe first worksheet \\"Updates\\" has the back-and-forth update records for each ticket, indicating if the update is a public user message or agent reply, or an internal message by an Agent.\\r\\n\\r\\n![Support ticket updates](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-31--01.png?raw=true)\\r\\n\\r\\nThe second worksheet \\"Assignment\\" has the ticket created versus ticket assigned date/time data.\\r\\n\\r\\n![Support ticket assignments](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-31--02.png?raw=true)\\r\\n\\r\\nThe third worksheet \\"Agents\\" has photo IDs that correlate to the images in this **[Github folder](https://github.com/datamesse/data-visualisation-datasets/tree/main/Support%20ticket%20updates/agents)**.\\r\\n\\r\\n![Support ticket agents](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-31--03.png?raw=true)\\r\\n\\r\\n![Support ticket agent photos](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-31--04.png?raw=true)\\r\\n\\r\\n\\r\\n**Why this dataset was created?**\\r\\n\\r\\nWorking in a global support team providing follow-the-sun (FTS) customer service, I wanted to be able to visualise the teamwork across staff members.\\r\\n\\r\\nAs I needed a fake dataset to test ideas on, I created an Excel file that randomly generated support ticket update information (e.g. when a end-user opens a ticket, when an agent first replies to the end-user, and the back-and-forth until the ticket becomes solved). The columns used in the dataset are meant to be similar to those seen in CRM systems that provide reporting on such ticket updates (e.g. Zendesk).\\r\\n\\r\\nI noticed my random generator did not account for the ticket IDs being in a realistic sequence, which needs to be amended after extracting the data from the generator. Also, the generator is limited in providing \\"follow-the-sun\\" support update records, so I spent some time manually editing records to demonstrate this in the sample dataset.\\r\\n\\r\\n\\r\\n**Disclaimer**\\r\\n\\r\\nThis dataset is free to use and alter as you need, and no attribution is required, though would be appreciated.\\r\\n\\r\\nAll names in this dataset are fictional and not based on real-life people. The random name generator that was used to create them can be found **[here](https://github.com/datamesse/excel-support-ticket-update-generator/blob/main/Random_name_and_business_generator.xlsx?raw=true)**.\\r\\n\\r\\nPhotographs were taken from **[Pixabay.com](https://pixabay.com/service/license/)** and **[Pexels.com](https://www.pexels.com/license/)** for non-commercial use, edited to fit the appearance of an organisational profile photo, and direct URL attribution included in the dataset for each photo.\\r\\n\\r\\nThe GitHub repository for this is **[here](https://github.com/datamesse/data-visualisation-datasets/tree/main/Support%20ticket%20updates)**.\\r\\n\\r\\nClick **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2021-10-31.md)** for this post\'s markdown file in GitHub."},{"id":1634994000,"title":"Calculate aggregate for grouped rows based on column value, DAX version","tag":"logo-powerbi","date":"October 24, 2021","content":"\\r\\nHow to use DAX to find the aggregate value for rows grouped by a column value in Power BI.\\r\\n\\r\\nIn a __[previous post](https://datamesse.github.io/#/post/1634389200/)__, I wrote on window aggregation equivalents in Power Query, going on the notion that categorical columns are generally better off done in Power Query using M code, as opposed to done in DAX.\\r\\n\\r\\nHowever, in a Power BI report I am working on, it seemed re-implementing it using DAX had faster report load times than Power Query, which I attributed to existing Power Query merges needed for the model, which slowed down processing. It also required having 2 columns in the model (one for the aggregation, and the other for the conditional result), unlike DAX which only required one.\\r\\n\\r\\nThat M code looked like this:\\r\\n\\r\\n**Power Query M structure**\\r\\n```\\r\\n    #\\"Added Custom 1\\" = Table.NestedJoin(#\\"Previous step\\",\\r\\n                                      {\\"Column A to join on\\"},\\r\\n                                      Table.Group(Table.SelectRows(#\\"Changed Type\\", each ([Column C] = \\"Agent\\")),\\r\\n                                                  {\\"Column A to join on\\"},\\r\\n                                                  {{\\"Result of aggregation\\",\\r\\n                                                  each List.Min([#\\"Column B to aggregate on\\"]), type nullable datetime}}),\\r\\n                                      {\\"Column A to join on\\"},\\r\\n                                      \\"Merged group by table\\",\\r\\n                                      JoinKind.Inner),\\r\\n    #\\"Expanded Merged group by table\\" = Table.ExpandTableColumn(#\\"Added Custom 1\\", \\"Merged group by table\\", {\\"Result of aggregation\\"}, {\\"Result of aggregation\\"}),\\r\\n    #\\"Added Custom 2\\" = Table.AddColumn(#\\"Expanded Merged group by table\\", \\"M column result\\", each if [#\\"Column B to aggregate on\\"] = [#\\"Result of aggregation\\"] then \\"Yes\\" else \\"No\\")\\r\\n```\\r\\n\\r\\nIn this example we\'re still using randomised support ticket update data, and trying to find which agent reply to the user is the first for each Ticket ID.\\r\\n\\r\\n![Sample dataset with only 15 rows of data](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--01.png?raw=true)\\r\\n\\r\\n\\r\\n**Power Query implementation**\\r\\n```\\r\\n    #\\"Added Custom\\" = Table.NestedJoin(#\\"Changed Type\\",\\r\\n                                      {\\"Ticket ID\\"},\\r\\n                                      Table.Group(Table.SelectRows(#\\"Changed Type\\", each ([Updater role] = \\"Agent\\")),\\r\\n                                                  {\\"Ticket ID\\"},\\r\\n                                                  {{\\"Earliest date/time by Ticket ID\\",\\r\\n                                                  each List.Min([#\\"Update - Timestamp\\"]), type nullable datetime}}),\\r\\n                                      {\\"Ticket ID\\"},\\r\\n                                      \\"Merged group by table\\",\\r\\n                                      JoinKind.Inner),\\r\\n    #\\"Expanded Merged group by table\\" = Table.ExpandTableColumn(#\\"Added Custom\\", \\"Merged group by table\\", {\\"Earliest date/time by Ticket ID\\"}, {\\"Earliest date/time by Ticket ID\\"}),\\r\\n    #\\"Added Custom1\\" = Table.AddColumn(#\\"Expanded Merged group by table\\", \\"1st reply?\\", each if [#\\"Update - Timestamp\\"] = [#\\"Earliest date/time by Ticket ID\\"] then \\"Yes\\" else \\"No\\")\\r\\nin\\r\\n    #\\"Added Custom1\\"\\r\\n```\\r\\n\\r\\n![Sample dataset with only 15 rows of data Power Query M code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--02.png?raw=true)\\r\\n\\r\\n\\r\\n![Sample dataset with only 15 rows of data Power Query performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--03.png?raw=true)\\r\\n\\r\\nNow let\'s look at the DAX alternative.\\r\\n\\r\\nIn DAX, we\'ve coded it as a new column, where an initial if condition is used to pre-determine the result for invalid rows (such as messages from client), and the nested false condition checks the remaining canidate rows (messages from agents) to see if the aggregate value (i.e. the earliest *Update - Timestamp*) matches for the existing row for each Ticket ID group.\\r\\n\\r\\n![Sample dataset with only 15 rows of data DAX Add New Column](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--04.png?raw=true)\\r\\n\\r\\n**DAX structure**\\r\\n```\\r\\nDAX column = IF([Column C] = \\"Column value of rows that should be excluded from aggregation\\",\\r\\n                \\"No\\",\\r\\n                IF(Tablename[Column B to aggregate on] = \\r\\n                    CALCULATE (\\r\\n                               MIN ( Tablename[Column B to aggregate on] ),\\r\\n                               FILTER(ALLEXCEPT (Tablename, Tablename[Column A to join on]), Tablename[Column C] = \\"Column value of rows to aggregate on\\" ))\\r\\n                              ,\\"Yes\\"\\r\\n                              ,\\"No\\"\\r\\n                )\\r\\n             )\\r\\n```\\r\\n\\r\\n**DAX implementation**\\r\\n```\\r\\n1st reply? = IF([Updater role] = \\"Client\\",\\r\\n                \\"No\\",\\r\\n                IF(Updates1[Update - Timestamp] = \\r\\n                    CALCULATE (\\r\\n                               MIN ( Updates1[Update - Timestamp] ),\\r\\n                               FILTER(ALLEXCEPT (Updates1, Updates1[Ticket ID]), Updates1[Updater role] = \\"Agent\\" ))\\r\\n                              ,\\"Yes\\"\\r\\n                              ,\\"No\\"\\r\\n                )\\r\\n             )\\r\\n```\\r\\n\\r\\n![Sample dataset with only 15 rows of data DAX code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--05.png?raw=true)\\r\\n\\r\\n\\r\\n![Sample dataset with only 15 rows of data DAX performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--06.png?raw=true)\\r\\n\\r\\n\\r\\nComparing the initial table refreshes from the screenshots above seems to indicate Power Query in this scenario is more performant than DAX.\\r\\n* DAX: 224ms\\r\\n* Power Query: 94ms\\r\\n\\r\\nHowever, this is a flat dataset with only 15 rows. So I set out to test it with a larger flat dataset (27780 rows), and if the results still show Power Query is more performant than DAX for categorical window aggregation, I would test a second time with that larger dataset, but using pre-existing merges to more closer reflect my model.\\r\\n\\r\\n\\r\\n**COMPARING DAX AND M FOR CATEGORICAL WINDOW AGGREGATION**\\r\\n\\r\\nThis blog post compares DAX vs Power Query (M) implementation of this scenario against:\\r\\n1. flat dataset using M for the window aggregation column\\r\\n2. flat dataset using DAX for the window aggregation column\\r\\n3. dataset with existing merge using M for the window aggregation column\\r\\n4. dataset with existing merge using DAX for the window aggregation column\\r\\n\\r\\n**Test 1: Flat dataset using M for the aggregation column**\\r\\n\\r\\n![Large flat dataset using M window aggregation M code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--07.png?raw=true)\\r\\n\\r\\nNote: Refresh 1 is when the column is first added to the visual.\\r\\n\\r\\n![Large flat dataset using M performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--09.png?raw=true)\\r\\n\\r\\n\\r\\n**Test 2: Flat dataset using DAX for the aggregation column**\\r\\n\\r\\n![Large flat dataset using M window aggregation DAX code](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--08.png?raw=true)\\r\\n\\r\\n\\r\\n![Large flat dataset using DAX](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--10.png?raw=true)\\r\\n\\r\\nNow we\'ve applied a simple merge to the dataset to display additional columns.\\r\\n![Large dataset with existing merge](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--11.png?raw=true)\\r\\n\\r\\n\\r\\n**Test 3: Merged dataset using M for the aggregation column**\\r\\n\\r\\n![Large dataset with existing merge using M performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--12.png?raw=true)\\r\\n\\r\\n\\r\\n![Large dataset with existing merge using DAX performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--15.png?raw=true)\\r\\n\\r\\n\\r\\n**Test 4: Merged dataset using DAX  for the aggregation column**\\r\\n\\r\\n![Large dataset with existing merge using DAX](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--13.png?raw=true)\\r\\n\\r\\n\\r\\n![Large dataset with existing merge using DAX performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--14.png?raw=true)\\r\\n\\r\\n\\r\\n![Large dataset with existing merge using DAX performance](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--16.png?raw=true)\\r\\n\\r\\nReviewing these table refresh times, it appears that for data sources involving a merge, using DAX for window aggregations is more performant than using Power Query, whereas it seems to be the reverse for data sources not involving merges.\\r\\n\\r\\n![Comparing table refresh times](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-24--17.png?raw=true)\\r\\n\\r\\nClick **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2021-10-24.md)** for this post\'s markdown file in GitHub."},{"id":1634389200,"title":"Find aggregate value for grouped rows based on column value","tag":"logo-powerbi","date":"October 17, 2021","content":"\\r\\nHow to use Power Query to find the aggregate value for rows grouped by a column value in Power BI.\\r\\n\\r\\nT-SQL uses the concept of window functions to perform aggregations across groupings of rows, which are based on a specific column\'s values. More info on this can be found on [Pinal Dave\'s blog](https://blog.sqlauthority.com/2015/05/28/sql-server-what-are-t-sql-window-functions-notes-from-the-field-082/).\\r\\n\\r\\n```\\r\\nTable.NestedJoin(#\\"Previous step in your Power Query code\\", \\r\\n                 {\\"Column(s) for left side of the join\\"}, \\r\\n                Table.Group(#\\"Previous step in your Power Query code\\", \\r\\n                             {\\"Column(s) to group by\\"}, \\r\\n                             {{\\"New column name for the aggregation result\\", \\r\\n                             each List.Min([#\\"Column to apply aggregation on\\"]), \\r\\n                             type nullable datatypeofyouraggregation}}),\\r\\n                 {\\"Column(s) for right side of the join\\"}, \\r\\n                 \\"New merged group by table name\\",\\r\\n                 JoinKind.Inner)\\r\\n```\\r\\n\\r\\nAs a basic example, say your dataset has rows representing quarterly sales and you need to calculate the proportion of sales which quarter represents for the whole year i.e. Quarterly Sales \xf7 Annual Sales.\\r\\n\\r\\nYou can do this by using a preliminary window function to first calculate annual sales by summing the rows based on shared year column values, providing that same value for each row of the group. Then for each row, calculate the proportion from there.\\r\\n\\r\\n![Example concept of Window function](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-17--01.png?raw=true)\\r\\n\\r\\nThe equivalent of Window functions in Power BI would typically be used for quantitative measures, and are thus more likely to be implemented using DAX calculations.\\r\\n\\r\\nHowever, there can be scenarios where window functions need to employed in a more categorical nature. Going by the general principle that custom measures (i.e. quantitative calculations) should be done in DAX, and that custom columns (typically categorical) should be done in Power Query, the latter is what we will employ here.\\r\\n\\r\\nIn this example scenario\'s dataset, we have 5 unique support ticket numbers, with each row representing an instance where a support agent has sent a response to the end-user for a ticket, as indicated by the date/timestamp.\\r\\n\\r\\n![Example categorical scenario of support ticket response date/timestamps](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-17--02.png?raw=true)\\r\\n\\r\\nOur objective is to create a column that identifies which rows of data represent the \\"first response\\" to the end-user for each ticket, with that intended 1st response flag being a rudimentary marker to help calculate other support agent statistics we may want (e.g. proportion of support tickets where the 1st responder is the assignee).\\r\\n\\r\\nThis is the equivalent of the previous example\'s proportion of annual sales that quarterly sales represents, in that the creation of a preliminary window function is needed. In our scenario, instead of doing a sum of sales based on rows sharing the same year, we will get the minimum (and hence the first) date/timestamps based on rows sharing the same ticket number.\\r\\n\\r\\nThe approach taken here is to create a new column whose definition is the combination of two common queries:\\r\\n1. The Table.NestedJoin function that\'s commonly seen in *Merge Queries* to combine your existing dataset to the conceptual grouped dataset.\\r\\n2. The Table.Group function creates a conceptual grouped by table of the existing dataset with the desired aggregate result, and that conceptual table being passed as the right-joined table parameter into the Table.NestedJoin.\\r\\n3. Then expand the merged table to display the aggregate result for each row of the original dataset.\\r\\n\\r\\n**Code structure**\\r\\n\\r\\n```\\r\\nTable.NestedJoin(#\\"Previous step in your Power Query code\\", \\r\\n                 {\\"Column(s) for left side of the join\\"}, \\r\\n                Table.Group(#\\"Previous step in your Power Query code\\", \\r\\n                             {\\"Column(s) to group by\\"}, \\r\\n                             {{\\"New column name for the aggregation result\\", \\r\\n                             each List.Min([#\\"Column to apply aggregation on\\"]), \\r\\n                             type nullable datatypeofyouraggregation}}),\\r\\n                 {\\"Column(s) for right side of the join\\"}, \\r\\n                 \\"New merged group by table name\\",\\r\\n                 JoinKind.Inner)\\r\\n```\\r\\n\\r\\n**Example**\\r\\n\\r\\nApplying the code structure above, the M code would be as below:\\r\\n\\r\\n![M code with merged](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-17--03.png?raw=true)\\r\\n\\r\\n```\\r\\n    #\\"Added Custom\\" = Table.NestedJoin(#\\"Changed Type\\", \\r\\n                                       {\\"Ticket ID\\"},\\r\\n                                       Table.Group(#\\"Changed Type\\",\\r\\n                                                   {\\"Ticket ID\\"},\\r\\n                                                   {{\\"1st response\\",\\r\\n                                                   each List.Min([#\\"Update - Timestamp\\"]), type nullable datetime}}),\\r\\n                                       {\\"Ticket ID\\"},\\r\\n                                       \\"Merged group by table\\",\\r\\n                                       JoinKind.Inner)\\r\\n```\\r\\n\\r\\nThe result of the new column addition (which is a merged table), will appear as below.\\r\\n\\r\\n![Power Query with new column for merged Group By table](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-17--04.png?raw=true)\\r\\n\\r\\nThen you simply need to expand out the aggregate column from the merge.\\r\\n\\r\\n![Power Query expand merged Group By table to display the aggregate column 1](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-17--05.png?raw=true)\\r\\n\\r\\n![Power Query expand merged Group By table to display the aggregate column 2](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-17--06.png?raw=true)\\r\\n\\r\\nNow that the preliminary window function is complete, we can address the example objective of creating a custom column to indicate which data row per Ticket ID represents the first support agent response to an end-user, which is a simple if condition to compare the \\"Update - Timestamp\\" and \\"1st response\\" columns.\\r\\n\\r\\n![Power Query if condition for example custom column](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-17--07.png?raw=true)\\r\\n\\r\\n![Power Query final example custom column](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-17--08.png?raw=true)\\r\\n\\r\\nIn this way, regardless of how the data is sorted in Power Query, the records representing the 1st responses will remain.\\r\\n\\r\\nClick **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2021-10-17.md)** for this post\'s markdown file in GitHub."},{"id":1633784400,"title":"Dynamically apply time zone and daylight savings on date/times in Power BI","tag":"logo-powerbi","date":"October 10, 2021","content":"\\r\\nHow to use Power Query to apply time zone offsets based on daylight savings \\"anchors\\" on date/times using a parameter, and without needing a separate calendar table in Power BI.\\r\\n\\r\\nThe final product is being able to use a Parameter to select a desired time zone, and apply it to your dataset\'s \\"Date/Time\\" column, and produce a \\"Date/Time/Zone\\" value.\\r\\n![Power BI Tokyo example](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--01.png?raw=true)\\r\\n\\r\\nWhat makes this different from the DateTime.Zone function alone, is that this method respects when the UTC offset changes based on time zone by creating custom functions to do this.\\r\\n\\r\\nThis post incorporates my previous posts on [how to import time zone and daylight saving observations from Wikipedia](https://datamesse.github.io/#/post/1633183200), which indicate when different offsets are applied (e.g. first Sunday of October), and my post on [how to find the nth day of a month](https://datamesse.github.io/#/post/1632578400) to convert those into usable \\"anchors\\" to determine the offset value for the date/times.\\r\\n\\r\\n**Note:** This is not an appropriate solution to time zone application in terms of data accuracy, processing efficiency, and coding involved. Ideally a predefined dataset or an API with actual date/time values for observation period start/ends would be best.\\r\\n\\r\\nA good example of this can be found in [a blog post by John White](https://whitepages.unlimitedviz.com/2020/10/dynamic-time-zone-conversion-using-power-bi/)\\r\\n\\r\\nThis post shows how date/time anchor values can be used as an alternative way to solve this problem, which does not use calendar tables nor APIs.\\r\\n\\r\\nThis is the **[sample date/time dataset](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/Date_times_to_convert.xlsx?raw=true)** we will dynamically apply time zone offsets to via parameter selection.\\r\\n\\r\\nNote there is no time zone in the data itself, so assumptions made by any application (e.g. user\'s machine time zone) may be incorrect.\\r\\n![Sample date time dataset in Excel](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--02.png?raw=true)\\r\\n\\r\\n![Sample date time dataset imported into Power Query](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--03.png?raw=true)\\r\\n\\r\\nAfter importing the sample date/time dataset, we next import the combined time zone offset and daylight savings observation **[dataset](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/Time_zone_offsets_and_DST_observations.xlsx?raw=true)** created in this [post](https://datamesse.github.io/#/post/1633183200).\\r\\n\\r\\nAt this point, if you only need certain time zones to select from, you can filter for them here before proceeding.\\r\\n\\r\\n![Offset and observation dataset imported into Power Query](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--04.png?raw=true)\\r\\n\\r\\nNext, we will create a list from the Timezone column, to be used as the available selections of the parameter.\\r\\n\\r\\n![Power Query Convert to List Part A](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--05.png?raw=true)\\r\\n\\r\\n![Power Query Convert to List Part B](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--06.png?raw=true)\\r\\n\\r\\nThen set up the parameter itself to pull from that list.\\r\\n\\r\\n![Power Query Create new parameter](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--07.png?raw=true)\\r\\n\\r\\n![Power Query Manage Parameters Part A](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--08.png?raw=true)\\r\\n\\r\\n![Power Query Manage Parameters Part B](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--09.png?raw=true)\\r\\n\\r\\nNext, we create a new column in the sample dataset whose value is the parameter selection.\\r\\n\\r\\n![Power Query custom column for Parameter value Part A](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--10.png?raw=true)\\r\\n\\r\\n![Power Query custom column for Parameter value Part B](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--11.png?raw=true)\\r\\n\\r\\nThen merge the two datasets using that new custom column.\\r\\n![Power Query Merge Queries](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--12.png?raw=true)\\r\\n\\r\\n![Power Query Merge Queries](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--13.png?raw=true)\\r\\n\\r\\nWhilst expanding the merged table, we can prefix the column names, which may be useful if intending to merge multiple times, e.g. parameter for data source\'s actual time zone vs parameter for desired time zone. We will only do the merge once, in this example.\\r\\n\\r\\n![Power Query expand merge queries Part A](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--14.png?raw=true)\\r\\n\\r\\n![Power Query expand merge queries Part B](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--15.png?raw=true)\\r\\n\\r\\nOur next step is to create a custom column to convert our Date/Time value to match the time zone of the parameter selection. This is not as simple as appending an offset to our Date/Time value, because of these considerations\\r\\n\\r\\na. The need to account for different Date/Time offsets based on standard vs daylight savings.\\r\\n\\r\\nb. The anchor dataset (which determines whether or not daylight savings is applied) has a mix of data structures e.g. anchor date/times can be either UTC or local time-based, and can either have a specific date of the month, or relative day position of the month.\\r\\n\\r\\nc. The datasets\' standard and daylight saving offset values are in a text based structure e.g. \\"+10:00\\", rather than straight numbers, which are more easily consumed by Power Query functions (e.g. *DateTime.AddZone()*).\\r\\n\\r\\nBefore we create the custom column, we will need 3 custom functions.\\r\\n1. A simple suffix of the standard or daylight daylight offset to the Date/Time value to make it a DateTimeZone value, which we\'ll name **DatetimeToDatetimezone**.\\r\\n2. A slightly more complex function that pulls in all date anchor values to convert to an actual date. But it only lets single parameters to pass for the time anchor (which could be UTC or local time) and offset (standard or daylight saving), which we\'ll name **AnchorToDatetimezone**.\\r\\n3. The complex function that applies the time zone to the Date/Time value, factoring in daylight saving and standard time observation by using the previous two functions, which we\'ll name **DatetimeAppendZone**.\\r\\n\\r\\nBeginning with the simple **DatetimeToDatetimezone** custom function, which is meant to resolve consideration *c)*.\\r\\n\\r\\n![Power Query create custom function Part A](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--16.png?raw=true)\\r\\n\\r\\n![Power Query create custom function Part B](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--17.png?raw=true)\\r\\n\\r\\n```\\r\\nlet\\r\\n  DatetimeToDatetimezone = (DateTimestamp as datetime, Offset as nullable text) => \\r\\n    DateTimeZone.FromText(DateTime.ToText(DateTimestamp) & \\" \\" & Offset)\\r\\nin\\r\\n  DatetimeToDatetimezone\\r\\n```\\r\\n\\r\\n![Power Query create 1st custom function](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--18.png?raw=true)\\r\\n\\r\\nNext we create the second custom function **AnchorToDatetimezone**, which takes in the dependent date/time value to get the year, and nullable parameters for time, offset, and the anchors for month, day, and *n*th occurrence of the day within the month. It checks the data structure to create the anchor\'s date, and appends the time and offset values passed into it.\\r\\n\\r\\n* The first if condition checks that there are no incorrect nor incomplete data structures.\\r\\n* The first else if condition creates the date time zone if there is a date anchor e.g. \\"21st\\" of given month.\\r\\n* The second and third else if conditions convert to date time zones based on 1st, 2nd, 3rd, or 4th occurrence of specified day anchors, and are based on this previous [post](https://datamesse.github.io/#/post/1632578400).\\r\\n* The fourth and fifth if else conditions convert based on the last occurrence of the specified day anchor, based on the last section of that same [post](https://datamesse.github.io/#/post/1632578400).\\r\\n\\r\\n```\\r\\nlet\\r\\n  AnchorToDatetimezone = (DateTimestamp as datetime, MonthAnchor as nullable number, DayAnchor as nullable number, PositionAnchor as nullable number, DateAnchor as nullable number, Time as nullable time, Offset as nullable text) => \\r\\n  /* Error-handling based on insufficient data or incorrect value combination */\\r\\n  if (MonthAnchor = null) \\r\\n    or (DateAnchor = null and DayAnchor = null)\\r\\n    or (DateAnchor <> null and DayAnchor <> null)\\r\\n    or (DayAnchor <> null and PositionAnchor = null)\\r\\n    or (DayAnchor = null and PositionAnchor <> null)\\r\\n    or (Time = null)\\r\\n    or (Offset = null)\\r\\n  then \\"Incomplete data\\"\\r\\n  /* Applying time zone to DateTimestamp, with separate conditions for position anchor = 9 i.e. \\"Last\\" */\\r\\n  else if DateAnchor <> null\\r\\n    then Text.From(Date.Year(DateTimestamp)) & \\"/\\" & Text.From(MonthAnchor)  & \\"/\\" & Text.From(DateAnchor) & \\" \\" & Text.From(Time) & Offset\\r\\n  else if DayAnchor < 6 and PositionAnchor > 0 and PositionAnchor < 5\\r\\n  /* Optional parameter in Date.DayOfWeek 1 = Day.Monday will get Sunday, hence DayAnchor (Sunday = 0) + 1 */\\r\\n    then Text.From(Date.Year(DateTimestamp)) & \\"/\\" & Text.From(MonthAnchor) & \\"/\\" & Text.From( (7 - Date.DayOfWeek(Date.FromText(Text.From(Date.Year(DateTimestamp)) & \\"/\\" & Text.From(MonthAnchor) & \\"/1\\"), DayAnchor + 1)) + (-7 + (7 * PositionAnchor)) ) & \\" \\" & Text.From(Time) & Offset\\r\\n  /* Need to pass Day.Sunday to get Saturday */\\r\\n  else if DayAnchor = 6 and PositionAnchor > 0 and PositionAnchor < 5\\r\\n    then Text.From(Date.Year(DateTimestamp)) & \\"/\\" & Text.From(MonthAnchor) & \\"/\\" & Text.From( (7 - Date.DayOfWeek(Date.FromText(Text.From(Date.Year(DateTimestamp)) & \\"/\\" & Text.From(MonthAnchor) & \\"/1\\"), Day.Sunday )) + (-7 + (7 * PositionAnchor)) ) & \\" \\" & Text.From(Time) & Offset\\r\\n  /* handling for last specific day of month */\\r\\n  else if DayAnchor = 0 and PositionAnchor = 9\\r\\n    then Text.From(Date.AddDays(Date.EndOfMonth(Date.From(Text.From(Date.Year(DateTimestamp)) & \\"/\\" & Text.From(MonthAnchor) & \\"/1\\")),(-1 * Number.From(Date.DayOfWeek(Date.EndOfMonth(Date.From(Text.From(Date.Year(DateTimestamp)) & \\"/\\" & Text.From(MonthAnchor) & \\"/1\\")), Day.Sunday))))) & \\" \\" & Text.From(Time) & Offset\\r\\n  else if DayAnchor > 0 and PositionAnchor = 9\\r\\n    then Text.From(Date.AddDays(Date.EndOfMonth(Date.From(Text.From(Date.Year(DateTimestamp)) & \\"/\\" & Text.From(MonthAnchor) & \\"/1\\")),(-1 * (Number.From(Date.DayOfWeek(Date.EndOfMonth(Date.From(Text.From(Date.Year(DateTimestamp)) & \\"/\\" & Text.From(MonthAnchor) & \\"/1\\")), Day.Sunday)) + ( 7 - DayAnchor ))))) & \\" \\" & Text.From(Time) & Offset\\r\\n  else null\\r\\nin\\r\\n  AnchorToDatetimezone\\r\\n```\\r\\n\\r\\n![Power Query create 2nd custom function](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--19.png?raw=true)\\r\\n\\r\\nThe third custom function **DatetimeAppendZone** uses the **AnchorToDatetimezone** custom function to create date/time anchors for the start and end of daylight savings, then compares them with the Date/Time value to determine if standard or daylight savings offsets should be suffixed to the Date/Time value, using the **DatetimeToDatetimezone** custom function.\\r\\n\\r\\nSome data sources may be incorrectly failing to account for daylight savings differences. In this third custom function, you can use the \\"Difference\\" parameter to add/subtract the missed hour(s) to compensate for those. The code below does not do that, but you can add it in, if required.\\r\\n\\r\\n```\\r\\nlet\\r\\n  DatetimeAppendZone = (DateTimestamp as datetime, Difference as number, StandardOffset as nullable text, DaylightOffset as nullable text, DSTstartAncDate as nullable number, DSTstartAncPosition as nullable number, DSTstartAncDay as nullable number, DSTstartAncMonth as nullable number, DSTstartAncUTC as nullable time, DSTstartAncLocal as nullable time, DSTendAncDate as nullable number, DSTendAncPosition as nullable number, DSTendAncDay as nullable number, DSTendAncMonth as nullable number, DSTendAncUTC as nullable time, DSTendAncLocal as nullable time) => \\r\\n  /* Validation to ensure same time anchor types for start and end are used */\\r\\n  if Difference <> 0 and ( (DSTstartAncLocal = null and DSTstartAncUTC = null) or (DSTendAncLocal = null and DSTendAncUTC = null) )\\r\\n    then \\"Incomplete data\\"\\r\\n\\r\\n  /* Where DST is not observed, just append Standard UTC offset */\\r\\n  else if Difference = 0\\r\\n    then DatetimeToDatetimezone(DateTimestamp, StandardOffset)\\r\\n\\r\\n  /* From this point on, if using a data source that doesn\'t properly account for Daylight Savings offsets, you can factor those into the calculations */\\r\\n\\r\\n  /* Where DST is observed with Standard time result */\\r\\n  else if Difference <> 0\\r\\n    and (\\r\\n          (\\r\\n           /* Where local offset is used, 1 DST period in same year, datetimestamp is outside daylight savings */\\r\\n           DSTstartAncLocal <> null and DSTstartAncMonth < DSTendAncMonth\\r\\n           and ( DatetimeToDatetimezone(DateTimestamp,StandardOffset) < DateTimeZone.From(AnchorToDatetimezone(DateTimestamp, DSTstartAncMonth, DSTstartAncDay, DSTstartAncPosition, DSTstartAncDate, DSTstartAncLocal, StandardOffset))\\r\\n                or DatetimeToDatetimezone(DateTimestamp,StandardOffset) > DateTimeZone.From(AnchorToDatetimezone(DateTimestamp, DSTendAncMonth, DSTendAncDay, DSTendAncPosition, DSTendAncDate, DSTendAncLocal, StandardOffset)) )\\r\\n          )\\r\\n      or  (\\r\\n           /* Where local offset is used, 2 DST periods in same year, datetimestamp is outside both daylight savings periods */\\r\\n           DSTstartAncLocal <> null and DSTstartAncMonth > DSTendAncMonth \\r\\n           and Date.Month(DateTimestamp) >= DSTendAncMonth and Date.Month(DateTimestamp) <= DSTstartAncMonth\\r\\n           and DatetimeToDatetimezone(DateTimestamp,DaylightOffset) > DateTimeZone.From(AnchorToDatetimezone(DateTimestamp, DSTendAncMonth, DSTendAncDay, DSTendAncPosition, DSTendAncDate, DSTendAncLocal, DaylightOffset))\\r\\n           and DatetimeToDatetimezone(DateTimestamp,DaylightOffset) < DateTimeZone.From(AnchorToDatetimezone(Date.AddYears(DateTimestamp,1), DSTstartAncMonth, DSTstartAncDay, DSTstartAncPosition, DSTstartAncDate, DSTstartAncLocal, DaylightOffset))           \\r\\n          )\\r\\n      or  (\\r\\n           /* Where UTC offset is used, 1 DST period in same year, datetimestamp is inside daylight savings */\\r\\n           DSTstartAncUTC <> null and DSTstartAncMonth < DSTendAncMonth\\r\\n           and ( DateTimeZone.ToUtc(DatetimeToDatetimezone(DateTimestamp,StandardOffset)) <  DateTimeZone.FromText(AnchorToDatetimezone(DateTimestamp, DSTstartAncMonth, DSTstartAncDay, DSTstartAncPosition, DSTstartAncDate, DSTstartAncUTC, \\"+00:00\\"))\\r\\n                 or DateTimeZone.ToUtc(DatetimeToDatetimezone(DateTimestamp,StandardOffset)) > DateTimeZone.FromText(AnchorToDatetimezone(DateTimestamp, DSTendAncMonth, DSTendAncDay, DSTendAncPosition, DSTendAncDate, DSTendAncUTC, \\"+00:00\\")) )\\r\\n          )\\r\\n    )\\r\\n    then DatetimeToDatetimezone(DateTimestamp, StandardOffset)\\r\\n\\r\\n  /* Where DST is observed with Dayliht Saving time result */\\r\\n  else if Difference <> 0\\r\\n    and (\\r\\n          (\\r\\n           /* Where local offset is used, 1 DST period within same year, datetimestamp is inside daylight savings */    \\r\\n           DSTstartAncLocal <> null and DSTstartAncMonth < DSTendAncMonth\\r\\n           and ( DatetimeToDatetimezone(DateTimestamp,StandardOffset) >= DateTimeZone.From(AnchorToDatetimezone(DateTimestamp, DSTstartAncMonth, DSTstartAncDay, DSTstartAncPosition, DSTstartAncDate, DSTstartAncLocal, StandardOffset))\\r\\n                or DatetimeToDatetimezone(DateTimestamp,StandardOffset) <= DateTimeZone.From(AnchorToDatetimezone(DateTimestamp, DSTendAncMonth, DSTendAncDay, DSTendAncPosition, DSTendAncDate, DSTendAncLocal, StandardOffset)) )\\r\\n          )\\r\\n      or  (\\r\\n           /* Where local offset is used, 2 DST periods in same year, datetimestamp is inside 1st daylight savings period */\\r\\n           DSTstartAncLocal <> null and DSTstartAncMonth > DSTendAncMonth and Date.Month(DateTimestamp) <= DSTendAncMonth\\r\\n           and DatetimeToDatetimezone(DateTimestamp,DaylightOffset) <= DateTimeZone.From(AnchorToDatetimezone(DateTimestamp, DSTendAncMonth, DSTendAncDay, DSTendAncPosition, DSTendAncDate, DSTendAncLocal, DaylightOffset))\\r\\n          )\\r\\n      or  (\\r\\n           /* Where local offset is used, 2 DST periods in same year, datetimestamp is inside 2nd daylight savings period */\\r\\n           DSTstartAncLocal <> null and DSTstartAncMonth > DSTendAncMonth and Date.Month(DateTimestamp) >= DSTendAncMonth\\r\\n           and DatetimeToDatetimezone(DateTimestamp,DaylightOffset) >= DateTimeZone.From(AnchorToDatetimezone(DateTimestamp, DSTstartAncMonth, DSTstartAncDay, DSTstartAncPosition, DSTstartAncDate, DSTstartAncLocal, DaylightOffset))\\r\\n          )\\r\\n      or  (\\r\\n           /* Where UTC offset is used, 1 DST period in same year, datetimestamp is outside daylight savings */\\r\\n           DSTstartAncUTC <> null and DSTstartAncMonth < DSTendAncMonth\\r\\n           and DateTimeZone.ToUtc(DatetimeToDatetimezone(DateTimestamp,StandardOffset)) >=  DateTimeZone.From(AnchorToDatetimezone(DateTimestamp, DSTstartAncMonth, DSTstartAncDay, DSTstartAncPosition, DSTstartAncDate, DSTstartAncUTC, \\"+00:00\\"))\\r\\n           and DateTimeZone.ToUtc(DatetimeToDatetimezone(DateTimestamp,StandardOffset)) <= DateTimeZone.From(AnchorToDatetimezone(DateTimestamp, DSTendAncMonth, DSTendAncDay, DSTendAncPosition, DSTendAncDate, DSTendAncUTC, \\"+00:00\\")) \\r\\n          )\\r\\n    )\\r\\n    then DatetimeToDatetimezone(DateTimestamp, DaylightOffset)\\r\\n  else null\\r\\nin\\r\\n  DatetimeAppendZone\\r\\n```\\r\\n\\r\\n![Power Query create 3rd custom function](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--20.png?raw=true)\\r\\n\\r\\nNow that our functions are complete, we can use the third **DatetimeAppendZone** to create the custom column which converts Date/Time to a datetimezone value, by passing in all the respective anchors as parameters.\\r\\n\\r\\n```\\r\\nDatetimeAppendZone([#\\"Date/Time\\"],[#\\"Daylight offset - Standard offset\\"],[Standard UTC offset],[Daylight Saving UTC offset],[#\\"DST start (date anchor)\\"],[#\\"DST start (position anchor)\\"],[#\\"DST start (day anchor)\\"],[#\\"DST start (month anchor)\\"],[#\\"DST start (UTC time anchor)\\"],[#\\"DST start (local time anchor)\\"],[#\\"DST end (date anchor)\\"],[#\\"DST end (position anchor)\\"],[#\\"DST end (day anchor)\\"],[#\\"DST end (month anchor)\\"],[#\\"DST end (UTC time anchor)\\"],[#\\"DST end (local time anchor)\\"])\\r\\n```\\r\\n\\r\\n![Power BI Create report](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--21.png?raw=true)\\r\\n\\r\\nIf we now create a table in the Power BI\'s report designer, we can see the appropriate suffixing of standard vs daylight saving offsets to our Date/Time values as we change the parameter. Then we can test to see if, regardless of the data structure used for the daylight savings anchoring, that the appropriate offset is applied to our Date/Time dataset.\\r\\n\\r\\nAustralia, Sydney is a time zone that uses local time and non-\\"last position\\" for its daylight savings start and end anchors.\\r\\n![Power BI Sydney example Part A](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--22a.png?raw=true)\\r\\n\\r\\n![Power BI Sydney example Part B](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--22.png?raw=true)\\r\\n\\r\\nEurope, Dublin is a time zone that uses UTC time and \\"last position\\" (indicated by the 9), for its anchors.\\r\\n![Power BI Dublin example Part A](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--23a.png?raw=true)\\r\\n\\r\\n![Power BI Dublin example Part B](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--23.png?raw=true)\\r\\n\\r\\nAfrica, Casablanca is a time zone that uses a fixed date of the month for its anchors.\\r\\n![Power BI Casablanca example Part A](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--24a.png?raw=true)\\r\\n\\r\\n![Power BI Casablanca example Part B](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-10--24.png?raw=true)\\r\\n\\r\\nSo now we have created a parameterised way of defining our data source\'s time zone, with potential to compensate for skipped daylight savings conversions it may have, by using the concept of anchor values to construct relative date/times.\\r\\n\\r\\nUse cases for this include:\\r\\n1. Dynamically converting date/times to another time zone e.g. a report reader from one time zone wanting to know the date/times from the perspective of another time zone.\\r\\n2. The admittedly rare instance where the time zone of date/times may vary at access or export when creating a datset.\\r\\n\\r\\nAn example where I encountered use case #2, was manually exporting data from Explore, the reporting tool for the Zendesk customer service platform, where date/times are automatically converted to match the time zone of the extractor\'s Zendesk login.\\r\\n\\r\\nIn that scenario, if multiple people from different time zones are creating or maintaining dashboards not made in the native Explore tool (e.g. via Power BI), their extract date times can be inconsistent.\\r\\n\\r\\nThere are simple ways around this:\\r\\n* Creating a shared account fixed to a specific time zone for data extracts.\\r\\n* Having access to the data source\'s API.\\r\\n\\r\\nYou can take this further for other solutions, such as hard-coding the desired time zone, or make it based on the values of another column e.g. time zone is based on country or city values.\\r\\n\\r\\n\\r\\nClick **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2021-10-10.md)** for this post\'s markdown file in GitHub."},{"id":1633183200,"title":"Import time zone offsets and observations from Wikipedia in Power BI","tag":"logo-powerbi","date":"October 3, 2021","content":"\\r\\nHow to use Power BI to scrape Wikipedia pages and create a data source for UTC time zone offsets and daylight saving observation anchors (e.g. the first Sunday of October).\\r\\n\\r\\nHere we will be importing Wikipedia table data from 2 different pages. The first example contains structured data values requiring minimal data cleaning. The second contains data which requires disaggregation of qualitative information to make it more quantitative.\\r\\n\\r\\nTime zone offset hours\\r\\n[https://en.wikipedia.org/wiki/List_of_tz_database_time_zones](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)\\r\\n\\r\\n![Wikipedia List of tz database time zones](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--01.png?raw=true)\\r\\n\\r\\nDaylight Saving observation period anchors\\r\\n[https://en.wikipedia.org/wiki/Daylight_saving_time_by_country](https://en.wikipedia.org/wiki/Daylight_saving_time_by_country)\\r\\n\\r\\n![Wikipedia Daylight saving time by country](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--02.png?raw=true)\\r\\n\\r\\n**Exercise 1:**\\r\\n\\r\\nBeginning with the time zone offset hours, we Get Data from Web and provide the URL.\\r\\n\\r\\n![Power BI Import data from a web page](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--03.png?raw=true)\\r\\n\\r\\nSelect the Basic option. The intention is to export the results to Excel, as opposed to a live ongoing connection. This is to mitigate problems regarding source page changes and connection delays.\\r\\n\\r\\n![Power BI Import data Basic setting and set URL](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--04.png?raw=true)\\r\\n\\r\\nThe HTML table we are after is the list containing the offsets.\\r\\nTick it, then click Transform Data.\\r\\n\\r\\n![Power BI Import data web page table selection](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--05.png?raw=true)\\r\\n\\r\\nNext we Use First Row as Headers to assign the column names.\\r\\n\\r\\n![Power Query Use First Row as Headers](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--06.png?raw=true)\\r\\n\\r\\nThen we add new custom columns to substitute existing columns to clean the data.\\r\\n\\r\\nFirst we add a new column to substitute the TZ database name column, replacing the single forward slashes \u201c/\u201d with forward slashes surrounded by spaces \u201c / \u201c, and replace the underscores \u201c_\u201d with spaces \u201c \u201c, for readability.\\r\\n\\r\\n```\\r\\nText.Replace(Text.Replace([TZ database name],\\"/\\", \\", \\"),\\"_\\",\\" \\")\\r\\n```\\r\\n\\r\\n![Power Query Replace text to make more readable](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--07.png?raw=true)\\r\\n\\r\\nSecondly, the data source\u2019s offsets use a different dash character \\"\u2212\\" (slightly longer) from the mathematical operator \\"-\\" (shorter), so we need to create custom columns to substitute the longer dash with the shorter one.\\r\\n\\r\\nFor the Standard UTC offset:\\r\\n\\r\\n```\\r\\nText.Replace([#\\"UTC offset \xb1hh:mm\\"],\\"\u2212\\",\\"-\\")\\r\\n```\\r\\n![Power Query Custom Column: Standard UTC offset](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--08.png?raw=true)\\r\\n\\r\\nFor the Daylight Saving UTC offset:\\r\\n\\r\\n```\\r\\nText.Replace([#\\"UTC DST offset \xb1hh:mm\\"],\\"\u2212\\",\\"-\\")\\r\\n```\\r\\n![Power Query Custom Column: Daylight Saving UTC offset](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--09.png?raw=true)\\r\\n\\r\\nNow to add a column that shows the difference between the standard and daylight savings offsets.\\r\\nThe nature of the data means you cannot subtract them in a simple way.\\r\\nComments are included in the code to explain what is occurring.\\r\\n\\r\\n```\\r\\n/* If the offsets are identical, it may imply no Daylight Saving observed */\\r\\nif [Standard UTC offset] = [Daylight Saving UTC offset]\\r\\nthen 0\\r\\n\\r\\n/* If minutes are the same and aren\'t zero, just subtract hours */\\r\\nelse if (Text.End([Standard UTC offset],2) <> \\"00\\" or \\r\\nText.End([Daylight Saving UTC offset],2) <> \\"00\\") and Text.End([Standard UTC offset],2) = Text.End([Daylight Saving UTC offset],2)\\r\\nthen Number.FromText(Text.Range([Daylight Saving UTC offset],0,3)) - Number.FromText(Text.Range([Standard UTC offset],0,3))\\r\\n\\r\\n/* If minutes are different and either of them aren\'t zero, convert minutes to proper decimals, subtract, then convert minutes back */\\r\\nelse if (Text.End([Standard UTC offset],2) <> \\"00\\" or \\r\\nText.End([Daylight Saving UTC offset],2) <> \\"00\\") and Text.End([Standard UTC offset],2) <> Text.End([Daylight Saving UTC offset],2)\\r\\nthen (Number.FromText(Text.Range([Daylight Saving UTC offset],1,2)) + (Number.FromText(Text.End([Daylight Saving UTC offset],2)) / 60)) - (Number.FromText(Text.Range([Standard UTC offset],1,2)) + (Number.FromText(Text.End([Standard UTC offset],2)) / 60))\\r\\n\\r\\n/* Standard expectation that difference is only in the hour values */\\r\\nelse Number.FromText(Text.Range([Daylight Saving UTC offset],1,2)) - Number.FromText(Text.Range([Standard UTC offset],1,2))\\r\\n```\\r\\n\\r\\n![Power Query Custom Column: Offset difference](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--10.png?raw=true)\\r\\n\\r\\nNext we filter out the data rows not required, starting with only including Canonical status offsets\\r\\n\\r\\n![Power Query Filter for Canonical records](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--11.png?raw=true)\\r\\n\\r\\nThen we filter for time zones that have a country code.\\r\\n\\r\\n![Power Query Filter for country codes](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--12.png?raw=true)\\r\\n\\r\\nLastly, remove columns that won\u2019t be needed, depending on what you need for your data source.\\r\\n\\r\\n![Power Query Remove other columns](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--13.png?raw=true)\\r\\n\\r\\nIn my scenario, I want to retain this data separately in an Excel file, so I create a table in Power BI with all the columns, then Export.\\r\\n\\r\\n![Power BI Export table results](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--14.png?raw=true)\\r\\n\\r\\n\\r\\n\\r\\n**Exercise 2:**\\r\\n\\r\\nFor our second dataset, we need to retrieve the relative anchors for daylight saving periods using the second URL: [https://en.wikipedia.org/wiki/Daylight_saving_time_by_country](https://en.wikipedia.org/wiki/Daylight_saving_time_by_country)\\r\\n\\r\\n![Power BI Import data Basic setting and set URL](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--15.png?raw=true)\\r\\n\\r\\nAgain, click Transform Data and Use First Row as Headers.\\r\\n\\r\\n![Power BI Import data web page table selection](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--16.png?raw=true)\\r\\n\\r\\n![Power Query Use First Row as Headers](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--17.png?raw=true)\\r\\n\\r\\nNext we filter for records with a valid current DST start value.\\r\\n\\r\\n![Power Query Filter for valid DST start](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--18.png?raw=true)\\r\\n\\r\\nThe problem with this dataset is that the DST start and DST end columns are not quantified at a low enough level to be easily worked with. Revising these columns, we can see value commonalities that can be separated out into custom columns as declartive \u201canchors\u201d for each daylight saving period\u2019s start and end.\\r\\n\\r\\nThis includes:\\r\\n* Positions (i.e. first, second, third, fourth, last)\\r\\n* Weekday names\\r\\n* Month names\\r\\n* \u201cUTC\u201d prefixed with a specific UTC time (e.g. 01:00 UTC), or prefixed with a non-UTC time (e.g. 002:00 AST (UTC-4)\\r\\n* Phrases \u201clocal standard time\u201d and \u201clocal daylight saving time\u201d prefixed with a time\\r\\n\\r\\n![Power Query Exploring qualitative data values](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--19.png?raw=true)\\r\\n\\r\\nThe custom columns are base conditions that check for substrings and substitute them with numerical data where possible, so they can be referenced by other custom functions.\\r\\n\\r\\nWe\u2019ll begin with the position-related column.\\r\\n\\r\\nEvery day has at least four occurrences in each month, but the \u201clast\u201d position could either be the fourth or fifth occurrence of that day. I chose to use an arbitrary value of 9 for the output of last, given 5 could possibly be used for the fifth instance of the day. Note: With this particular dataset, neither Fourth nor Fifth occur, so they can be omitted here if you want.\\r\\n\\r\\n```\\r\\nif Text.Contains([DST start], \\"First\\")\\r\\nthen 1\\r\\nelse if Text.Contains([DST start], \\"Second\\")\\r\\nthen 2\\r\\nelse if Text.Contains([DST start], \\"Third\\")\\r\\nthen 3\\r\\nelse if Text.Contains([DST start], \\"Fourth\\")\\r\\nthen 4\\r\\nelse if Text.Contains([DST start], \\"Fifth\\")\\r\\nthen 5\\r\\nelse if Text.Contains([DST start], \\"Last\\")\\r\\nthen 9\\r\\nelse null\\r\\n```\\r\\n\\r\\n![Power Query Custom Column: DST start position anchor](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--20.png?raw=true)\\r\\n\\r\\nNext to create a custom column for the weekdays, using Power Query\u2019s Day functions, which translate as numbers from 0 for Sunday to 6 for Saturday.\\r\\n\\r\\n```\\r\\nif Text.Contains([DST start], \\"Sunday\\")\\r\\nthen Day.Sunday\\r\\nelse \\r\\nif Text.Contains([DST start], \\"Monday\\")\\r\\nthen Day.Monday\\r\\nelse \\r\\nif Text.Contains([DST start], \\"Tuesday\\")\\r\\nthen Day.Tuesday\\r\\nelse \\r\\nif Text.Contains([DST start], \\"Wednesday\\")\\r\\nthen Day.Wednesday\\r\\nelse \\r\\nif Text.Contains([DST start], \\"Thursday\\")\\r\\nthen Day.Thursday\\r\\nelse \\r\\nif Text.Contains([DST start], \\"Friday\\")\\r\\nthen Day.Friday\\r\\nelse \\r\\nif Text.Contains([DST start], \\"Saturday\\")\\r\\nthen Day.Saturday\\r\\nelse null\\r\\n```\\r\\n\\r\\n![Power Query Custom Column: DST start day anchor](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--21.png?raw=true)\\r\\n\\r\\nWe repeat with similar logic for the DST start field\u2019s month anchor. At time of writing, Power Query has a function that converts month numbers to month names, but not the other way around.\\r\\n\\r\\n```\\r\\nif Text.Contains([DST start], \\"January\\")\\r\\nthen 1\\r\\nelse if Text.Contains([DST start], \\"February\\")\\r\\nthen 2\\r\\nelse if Text.Contains([DST start], \\"March\\")\\r\\nthen 3\\r\\nelse if Text.Contains([DST start], \\"April\\")\\r\\nthen 4\\r\\nelse if Text.Contains([DST start], \\"May\\")\\r\\nthen 5\\r\\nelse if Text.Contains([DST start], \\"June\\")\\r\\nthen 6\\r\\nelse if Text.Contains([DST start], \\"July\\")\\r\\nthen 7\\r\\nelse if Text.Contains([DST start], \\"August\\")\\r\\nthen 8\\r\\nelse if Text.Contains([DST start], \\"September\\")\\r\\nthen 9\\r\\nelse if Text.Contains([DST start], \\"October\\")\\r\\nthen 10\\r\\nelse if Text.Contains([DST start], \\"November\\")\\r\\nthen 11\\r\\nelse if Text.Contains([DST start], \\"December\\")\\r\\nthen 12\\r\\nelse null\\r\\n```\\r\\n\\r\\n![Power Query Custom Column: DST start month anchor](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--22.png?raw=true)\\r\\n\\r\\nLastly, we will pull where a UTC time is specified. There are entries where a local time with its UTC offset value is provided, but since these entries are few and complex to manage, I will edit the export result afterward to account for these. It\u2019s a cost vs benefit juggle.\\r\\n\\r\\n```\\r\\nif Text.Contains([DST start], \\" UTC\\") then Text.Range([DST start], Text.PositionOf([DST start],\\" UTC\\") - 5, 5) else null\\r\\n```\\r\\n\\r\\n![Power Query Custom Column: DST start UTC time anchor](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--23.png?raw=true)\\r\\n\\r\\nRinse-and-repeat the creation of those anchor columns. An alternative is creating a custom function to make it easier to manage later on.\\r\\n\\r\\n![Power Query Custom Columns for DST end](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--24.png?raw=true)\\r\\n\\r\\nThen we can retain the columns we need, such as Country/Territory, Notes, and the custom columns we created.\\r\\n\\r\\n![Power Query Remove other columns](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--25.png?raw=true)\\r\\n\\r\\nLastly, as with the previous dataset, we will export this to Excel, and clean up the file from there, e.g. accounting for records that have a different data structure for their anchors, such as an exact date for day and month per year, and records that include local time, etc.\\r\\n\\r\\n![Power BI Export table results](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--26.png?raw=true)\\r\\n\\r\\nAt this point, we typically would merge these datasets, similar to left outer joins in SQL. Unfortunately, the first dataset uses an incoherent structure for its time zone name values, e.g. _country, city_ or _region, city_ or _region, country, city_ etc., as opposed to the second data set, which only lists country.\\r\\n\\r\\n![Power Query Merge Queries](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--27.png?raw=true)\\r\\n\\r\\nI tried fuzzy matching, but as at time of writing, it cannot connect a high enough number of the records, regardless of adjustments made to the accuracy.\\r\\n\\r\\n![Power Query Merge using fuzzy matching](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--28.png?raw=true)\\r\\n\\r\\nAn alternative solution would be to create a list based on the second dataset\u2019s county column, but this would neglect the _region, city_ joins from the first dataset. Another would be to find a third dataset to extend the other datasets and formulate a common column for the merge.\\r\\n\\r\\nIn my scenario, it would be more time efficient to do the mapping manually, as this dataset is small, and intended for a niche non-scaled need. \\r\\n\\r\\nFind a copy of the end product to download as an Excel file **[here](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/Time_zone_offsets_and_DST_observations.xlsx?raw=true)**.\\r\\n\\r\\nAs a reminder, this is strictly an exercise file, and its data is not comprehensive nor accurate, so please be mindful of that if using it.\\r\\n\\r\\n![Manually cleaned output](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-10-03--29.png?raw=true)\\r\\n\\r\\nClick **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2021-10-03.md)** for this post\'s markdown file in GitHub."},{"id":1632578400,"title":"Find date for the nth day of a month in Power BI","tag":"logo-powerbi","date":"September 26, 2021","content":"\\r\\nHow to use Power Query to find the date for the nth day of a month/year based on another date column (e.g. 3rd Tuesday of October 2021).\\r\\n\\r\\nIn Power BI this can be used for the conditional logic of other Custom Columns. For example, to create indicators that data rows occur on or fall between relative date ranges (e.g. Black Friday sales). The following involves adding a Custom Column in Power Query i.e. M code, not DAX.\\r\\n\\r\\nThis finds the first Monday of the month, where our dependent date column is OurDateField.\\r\\n\\r\\n```\\r\\nDate.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/\\" & Text.From((7 - (Date.DayOfWeek(Date.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/1\\"),Day.Monday)))))\\r\\n```\\r\\n\\r\\n![Power Query: 1st Sunday of month](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--01.png?raw=true)\\r\\n\\r\\n**How it works**\\r\\n\\r\\nTo find the first Sunday of a specific month/year relative to another date, first establish the start of the month e.g. 1/10 (1st October), passing in the date field you are using e.g. [OurDateField], to append its year.\\r\\n\\r\\n```\\r\\nDate.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/1\\")\\r\\n```\\r\\n\\r\\nIn this example, we are hard-coding October regardless of OurDateField\u2019s month value, but if you need it to be relative to its month too, simply add an extra concatenation for month in the same way year is treated, i.e. using Date.Month().\\r\\n\\r\\nNow we need to identify what day of the week that this first day of the month is, using Date.DayOfWeek, and setting the optional parameter for what the start of the week is, as Day.Monday\\r\\n\\r\\n```\\r\\nDate.DayOfWeek(Date.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/1\\"),Day.Monday)\\r\\n```\\r\\n\\r\\n![Power Query: Day of week number](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--02.png?raw=true)\\r\\n\\r\\n \\r\\nIn this example, 1st October 2021 is a Friday, and Friday\u2019s day number is 4 (with Monday being 0).\\r\\n\\r\\n![Calendar: Weekday of 1st day of month](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--03.png?raw=true)\\r\\n\\r\\nIf you do not provide the Day.Monday parameter, it will default to Day.Monday in the background. If another parameter is used e.g. Day.Sunday, then the assignment numbers will change.\\r\\n\\r\\nNow we subtract the weekday number 4 from 7, and get 3, which is the first Sunday\u2019s date.\\r\\n\\r\\n```\\r\\n7 - (Date.DayOfWeek(Date.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/1\\"),Day.Monday))\\r\\n```\\r\\n\\r\\n![Power Query: Date of 1st Sunday](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--04.png?raw=true)\\r\\n\\r\\nThen concatenate this with the year month retrieved earlier\\r\\n\\r\\n```\\r\\nDate.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/\\" & Text.From((7 - (Date.DayOfWeek(Date.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/1\\"),Day.Monday)))))\\r\\n```\\r\\n\\r\\n![Power Query: Concatenate the month year to the date](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--05.png?raw=true)\\r\\n\\r\\nIf you need to change the weekday that Power Query needs to find, simply increment the Day.Monday parameter to the following day of the desired weekday.\\r\\n\\r\\nFor example, if you want to find the first Wednesday, change the parameter to Day.Thursday.\\r\\n\\r\\n```\\r\\nDate.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/\\" & Text.From((7 - (Date.DayOfWeek(Date.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/1\\"),Day.Thursday)))))\\r\\n```\\r\\n\\r\\n![Power Query: 1st Wednesday of month](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--06.png?raw=true)\\r\\n\\r\\n![Calendar: 1st Wednesday of the month](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--07.png?raw=true)\\r\\n\\r\\nIf you need to change the position from first, to second, third, or fourth Sunday, simply add 7 for the second, 14 for the third, and 21 for the fourth.\\r\\n\\r\\nFor example, we will retrieve the 3rd Sunday.\\r\\n\\r\\n```\\r\\nDate.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/\\" & Text.From((7 - (Date.DayOfWeek(Date.FromText(Text.From(Date.Year([OurDateField])) & \\"/10/1\\"),Day.Monday)) + 14 )))\\r\\n```\\r\\n\\r\\n![Calendar: 3rd Sunday of the month](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--08.png?raw=true)\\r\\n\\r\\n\\r\\n\\r\\n**Edit: 9th October 2021**\\r\\n\\r\\nIf the last occurrence of a specific day in a month needs to be retrieved, it can possibly be the 4th or 5th instance of that day. Retrieving this may be required for conditional or other custom column dependencies. \\r\\n\\r\\nAs an example, this Power Query code finds the last Sunday of the month, where our dependent date column is OurDateField.\\r\\n\\r\\n```\\r\\nDate.AddDays(Date.EndOfMonth([OurDateField]),(-1 * Number.From(Date.DayOfWeek(Date.EndOfMonth([OurDateField]), Day.Sunday))))\\r\\n```\\r\\n![Power Query Day number of last of the month year Day.Sunday](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--12.png?raw=true)\\r\\n\\r\\n**How it works**\\r\\n\\r\\nWe will try to retrieve the last Sunday of a specific month/year, passing in our relative *OurDateField*.\\r\\n\\r\\n```\\r\\nDate.EndOfMonth([OurDateField])\\r\\n```\\r\\n![Power Query last day of the month year](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--09.png?raw=true)\\r\\n\\r\\nThen find out which day of the week it is.\\r\\n\\r\\n```\\r\\nDate.DayOfWeek(Date.EndOfMonth([OurDateField]), Day.Monday)\\r\\n```\\r\\n![Power Query Day number of last of the month year Day.Monday](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--10.png?raw=true)\\r\\n\\r\\nIn this example, 31st January 2021 is a Sunday, and Sunday\u2019s day number is 6. This is if the optional parameter for start of the week is Day.Monday (which is the default, if not provided).\\r\\n\\r\\n![Calendar using Day.Monday](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--11.png?raw=true)\\r\\n\\r\\nNow we will swap that Day.Monday parameter out with Day.Sunday, so that the value for Sunday becomes 0 instead of 6.\\r\\n\\r\\n```\\r\\nDate.DayOfWeek(Date.EndOfMonth([OurDateField]), Day.Sunday)\\r\\n```\\r\\n![Power Query Day number of last of the month year Day.Sunday](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--12.png?raw=true)\\r\\n\\r\\n![Calendar using Day.Sunday](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--13.png?raw=true)\\r\\n\\r\\nWe then minus this number from the last date of the month, to get the last Sunday of the month, whih ironically is the same day i.e. Sunday 31/01/2021 - 0 = 31/01/2021. We do this using the Date.AddDays function and multiplying the number with -1.\\r\\n\\r\\n```\\r\\nDate.AddDays(Date.EndOfMonth([OurDateField]),(-1 * Number.From(Date.DayOfWeek(Date.EndOfMonth([OurDateField]), Day.Sunday))))\\r\\n```\\r\\n![Power Query last date Sunday](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--14.png?raw=true)\\r\\n\\r\\nLastly, if you need to pick any other last specific day of the month, just increment by one for each day you want to go earlier in the week e.g. Saturday is +1, Friday is +2 etc.\\r\\n\\r\\nFor example, the last Friday of the month year.\\r\\n\\r\\n```\\r\\nDate.AddDays(Date.EndOfMonth([OurDateField]),(-1 * (Number.From(Date.DayOfWeek(Date.EndOfMonth([OurDateField]), Day.Sunday)) + 2)))\\r\\n```\\r\\n![Power Query last date Friday](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--15.png?raw=true)\\r\\n\\r\\n![Power Query last date Friday](https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-blog/2021-09-26--16.png?raw=true)\\r\\n\\r\\nClick **[here](https://github.com/datamesse/datamesse.github.io/blob/main/src/posts/2021-09-26.md)** for this post\'s markdown file in GitHub."}]')},14:function(e,t,a){},34:function(e,t,a){},43:function(e,t,a){"use strict";a.r(t);var n=a(9),r=(a(1),a(21)),s=a.n(r),o=a(10),i=a(4),c=function(e){e&&e instanceof Function&&a.e(3).then(a.bind(null,47)).then((function(t){var a=t.getCLS,n=t.getFID,r=t.getFCP,s=t.getLCP,o=t.getTTFB;a(e),n(e),r(e),s(e),o(e)}))},d=(a(34),a(14),a.p+"static/media/bannervideo-bluerectangles2.56f34f60.mp4"),m=(a.p,a.p,a.p,a.p,a.p+"static/media/logo-github.69068f5c.svg"),h=a.p+"static/media/logo-html.aff8a9cb.svg",u=(a.p,a.p,a.p,a.p,a.p+"static/media/logo-powerbi.7a4f4c21.svg"),l=(a.p,a.p,a.p,a.p,a.p+"static/media/logo-tableau.be3c5104.svg"),g=a.p+"static/media/logo-twitter.d9f209d1.svg",p=(a.p,a.p,a.p,a.p+"static/media/logoblue-github.08098522.svg"),b=(a.p,a.p+"static/media/logoblue-powerbi.f400db81.svg"),A=a.p+"static/media/logoblue-tableau.35e372b8.svg",f=a.p+"static/media/logoblue-twitter.72da10de.svg",w=(a.p,String.fromCharCode(104,116,116,112,115,58,47,47,119,119,119,46,108,105,110,107,101,100,105,110,46,99,111,109,47,105,110,47),String.fromCharCode(74,46,32),String.fromCharCode(77,65,75,85),String.fromCharCode(72,65,82,73),a(0));function y(){return Object(w.jsx)("div",{className:"banner",children:Object(w.jsxs)("div",{className:"banner-navigation",children:[Object(w.jsx)("div",{className:"menu-overlay",children:Object(w.jsxs)("ul",{children:[Object(w.jsxs)("li",{children:[Object(w.jsx)("div",{className:"menu-overlay-glow"}),Object(w.jsx)(o.b,{to:"/",children:"PROJECTS"})]}),Object(w.jsxs)("li",{children:[Object(w.jsx)("div",{className:"menu-overlay-glow"}),Object(w.jsx)(o.b,{to:"/blog",children:"BLOG"})]})]})}),Object(w.jsxs)("center",{children:[Object(w.jsxs)("div",{className:"banner-title",children:[Object(w.jsx)("h4",{id:"title",children:"DATA MESSE"}),Object(w.jsx)("p",{children:"Analyst from Australia"})]}),Object(w.jsxs)("div",{className:"banner-elements",children:[Object(w.jsx)("img",{src:"data:image/jpeg;base64,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",class:"banner-avatar"}),Object(w.jsxs)("ul",{className:"banner-button-list",children:[Object(w.jsx)("li",{children:Object(w.jsxs)("a",{href:"https://github.com/datamesse/",target:"_blank",children:[Object(w.jsxs)("span",{className:"banner-icon",children:[Object(w.jsx)("img",{src:p}),Object(w.jsx)("img",{src:m})]}),Object(w.jsx)("span",{className:"banner-label",children:"GitHub"})]})}),Object(w.jsx)("li",{children:Object(w.jsxs)("a",{href:"https://community.powerbi.com/t5/forums/recentpostspage/post-type/message/category-id/PBI_Comm_Galleries/user-id/331466",target:"_blank",children:[Object(w.jsxs)("span",{className:"banner-icon",children:[Object(w.jsx)("img",{src:b}),Object(w.jsx)("img",{src:u})]}),Object(w.jsx)("span",{className:"banner-label",children:"Power BI"})]})}),Object(w.jsx)("li",{children:Object(w.jsxs)("a",{href:"https://public.tableau.com/profile/data.messe#!/",target:"_blank",children:[Object(w.jsxs)("span",{className:"banner-icon",children:[Object(w.jsx)("img",{src:A}),Object(w.jsx)("img",{src:l})]}),Object(w.jsx)("span",{className:"banner-label",children:"Tableau"})]})}),Object(w.jsx)("li",{children:Object(w.jsxs)("a",{href:"https://twitter.com/data_messe/",target:"_blank",children:[Object(w.jsxs)("span",{className:"banner-icon",children:[Object(w.jsx)("img",{src:f}),Object(w.jsx)("img",{src:g})]}),Object(w.jsx)("span",{className:"banner-label",children:"Twitter"})]})})]})]})]}),Object(w.jsx)("video",{class:"banner-video",autoPlay:!0,loop:!0,muted:!0,playsinline:!0,width:!0,children:Object(w.jsx)("source",{src:d,type:"video/mp4"})})]})})}function D(){var e=(new Date).getFullYear();return Object(w.jsx)("div",{className:"footer",children:Object(w.jsx)("center",{children:Object(w.jsxs)("p",{children:["data messe | \u24b8 ",e]})})})}var T=a.p+"static/media/img-2021-09-portfolio-website-react.154f6de5.png",x=a.p+"static/media/img-2021-10-power-bi-quarterly-singapore-rental-prices-by-currency.8745e860.png",S=a.p+"static/media/img-2021-11-power-bi-follow-the-sun-customer-support.5656c9fc.png",v=[{title:"Follow the sun customer support",description:"Power BI report showing teamwork and performance for global customer service",stamp:"2021-11",stack:u,photo:S,siteURL:"https://community.powerbi.com/t5/Data-Stories-Gallery/Follow-the-sun-customer-service-support/m-p/2168279",codeURL:"https://github.com/datamesse/data-visualisation-datasets/tree/main/Support%20ticket%20updates"},{title:"Singapore rental prices",description:"Power BI report showing trends of Singapore rent by quarter, major currency, and flat type",stamp:"2021-10",stack:u,photo:x,siteURL:"https://community.powerbi.com/t5/Data-Stories-Gallery/Quarterly-Singapore-median-rental-prices-by-currency/m-p/2125424",codeURL:"https://github.com/datamesse/data-visualisation-datasets/tree/main/Singapore%20rental%20prices"},{title:"Project portfolio",description:"My portfolio website coded using HTML, CSS, and JavaScript with React.js and GitHub Pages",stamp:"2021-09",stack:h,photo:T,siteURL:"https://datamesse.github.io/",codeURL:"https://github.com/datamesse/datamesse.github.io/"}];var j=a(15),C=a(13);function O(e){var t=parseInt(e.match.params.id);if(!t)return Object(w.jsx)(i.a,{to:"/404"});var a={},n=!1;return C.forEach((function(e,r){t===e.id&&(a.title=e.title?e.title:"No title given",a.tag=e.tag?e.tag:"No tag given",a.date=e.date?e.date:"No date given",a.content=e.content?e.content:"No content given",n=!0)})),!1===n?Object(w.jsx)(i.a,{to:"/404"}):Object(w.jsxs)(w.Fragment,{children:[Object(w.jsx)(y,{}),Object(w.jsx)("div",{className:"post",children:Object(w.jsx)("center",{children:Object(w.jsxs)("div",{className:"post-body",children:[Object(w.jsx)("h4",{children:a.date}),Object(w.jsx)("h1",{children:a.title}),Object(w.jsx)(j.a,{escapeHtml:!1,children:a.content})]})})}),Object(w.jsx)(D,{})]})}s.a.render(Object(w.jsx)(o.a,{children:Object(w.jsxs)("div",{children:[Object(w.jsx)(i.b,{exact:!0,path:"/",component:function(){return Object(w.jsxs)(w.Fragment,{children:[Object(w.jsx)(y,{}),Object(w.jsx)("div",{className:"projects",children:Object(w.jsx)("center",{children:Object(w.jsx)("div",{className:"project-set",children:v.map((function(e,t){return Object(w.jsxs)("div",{className:"project-tile",children:[Object(w.jsx)("span",{className:"stack-overlay",children:Object(w.jsx)("img",{src:e.stack,alt:""})}),Object(w.jsx)("div",{className:"stamp-overlay",children:e.stamp}),Object(w.jsx)("div",{className:"stack-overlaybg"}),Object(w.jsx)("img",{src:e.photo,alt:""}),Object(w.jsxs)("div",{className:"project-desc",children:[Object(w.jsx)("p",{className:"project-title",children:e.title}),Object(w.jsx)("p",{children:e.description})]}),Object(w.jsxs)("div",{className:"project-link",children:[Object(w.jsx)("a",{href:e.siteURL,target:"_blank",children:"SITE"}),Object(w.jsx)("a",{href:e.codeURL,target:"_blank",children:"CODE"})]})]},t)}))})})}),Object(w.jsx)(D,{})]})}}),Object(w.jsx)(i.b,{exact:!0,path:"/blog",component:function(){var e=C.map((function(e){return e.content.split(" ").slice(0,30).join(" ")+" . . . "}));return console.log(C),Object(w.jsxs)(w.Fragment,{children:[Object(w.jsx)(y,{}),Object(w.jsx)("div",{className:"blog",children:Object(w.jsx)("center",{children:Object(w.jsx)("div",{className:"project-set",children:C.length&&C.map((function(t,a){return Object(w.jsxs)("div",{className:"blog-tile",children:[Object(w.jsxs)("div",{className:"blog-tile-header",children:[Object(w.jsx)("span",{className:"blogstamp-overlay",children:Object(w.jsx)("img",{src:"".concat("https://raw.githubusercontent.com/datamesse/datamesse.github.io/main/src/assets-theme/").concat(t.tag,".svg"),alt:""})}),Object(w.jsx)(o.b,{to:"/post/".concat(t.id),children:t.title})]}),Object(w.jsx)("div",{className:"blog-meta",children:Object(w.jsx)("small",{children:t.date})}),Object(w.jsx)(j.a,{className:"blog-desc",escapeHtml:!1,children:e[a]}),Object(w.jsx)("div",{className:"blog-meta",children:Object(w.jsx)("small",{children:Object(w.jsx)(o.b,{to:"/post/".concat(t.id),children:"Read more..."})})}),Object(w.jsx)("div",{className:"blog-tile-footer"})]},a)}))})})}),Object(w.jsx)(D,{})]})}}),Object(w.jsx)(i.b,{exact:!0,path:"/404",component:function(){return Object(w.jsxs)(w.Fragment,{children:[Object(w.jsx)(y,{}),Object(w.jsx)("h1",{children:"The page you are looking for does not exist."})]})}}),Object(w.jsx)(i.b,{exact:!0,path:"/post/:id",render:function(e){return Object(w.jsx)(O,Object(n.a)({},e))}})]})}),document.getElementById("root")),c()}},[[43,1,2]]]);
//# sourceMappingURL=main.ad962413.chunk.js.map